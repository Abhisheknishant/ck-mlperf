{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [dividiti](http://dividiti.com)'s submissions to [MLPerf Inference v0.5](https://github.com/mlperf/inference/tree/master/v0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"overview\"></a>\n",
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter notebook covers [dividiti](http://dividiti.com)'s submissions to [MLPerf Inference v0.5](https://github.com/mlperf/inference/tree/master/v0.5). It validates that experimental data obtained via automated, portable and reproducible [Collective Knowledge](http://cknowledge.org) workflows conforms to [General MLPerf Submission Rules](https://github.com/mlperf/policies/blob/master/submission_rules.adoc)\n",
    "and [MLPerf Inference Rules](https://github.com/mlperf/inference_policies/blob/master/inference_rules.adoc), including runnning the official [`submission_checker.py`](https://github.com/mlperf/inference/blob/master/v0.5/tools/submission/submission-checker.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Overview](#overview)\n",
    "1. [Includes](#includes)\n",
    "1. [Systems](#systems)\n",
    "  1. [Firefly RK3399](#systems_firefly)\n",
    "  1. [Linaro HiKey960](#systems_hikey960)\n",
    "  1. [Huawei Mate 10 Pro](#systems_mate10pro)\n",
    "  1. [Raspberry Pi 4](#systems_rpi4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"includes\"></a>\n",
    "## Includes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import re\n",
    "\n",
    "from pprint import pprint\n",
    "from shutil import copy2\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scientific"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If some of the scientific packages are missing, please install them using:\n",
    "```\n",
    "# python3 -m pip install jupyter pandas numpy matplotlib seaborn --user\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython as ip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mp\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('IPython version: %s' % ip.__version__)\n",
    "print ('Pandas version: %s' % pd.__version__)\n",
    "print ('NumPy version: %s' % np.__version__)\n",
    "print ('Matplotlib version: %s' % mp.__version__)\n",
    "print ('Seaborn version: %s' % sb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "def display_in_full(df):\n",
    "    pd.options.display.max_columns = len(df.columns)\n",
    "    pd.options.display.max_rows = len(df.index)\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_colormap = cm.autumn\n",
    "default_fontsize = 16\n",
    "default_barwidth = 0.8\n",
    "default_figwidth = 24\n",
    "default_figheight = 3\n",
    "default_figdpi = 200\n",
    "default_figsize = [default_figwidth, default_figheight]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mp.__version__[0]=='2': mp.style.use('classic')\n",
    "mp.rcParams['figure.max_open_warning'] = 200\n",
    "mp.rcParams['figure.dpi'] = default_figdpi\n",
    "mp.rcParams['font.size'] = default_fontsize\n",
    "mp.rcParams['legend.fontsize'] = 'medium'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fig_dir = os.path.join(os.path.expanduser(\"~\"), 'mlperf-dividiti')\n",
    "if not os.path.exists(save_fig_dir):\n",
    "    os.mkdir(save_fig_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collective Knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If CK is not installed, please install it using:\n",
    "```\n",
    "# python -m pip install ck\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ck.kernel as ck\n",
    "print ('CK version: %s' % ck.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"systems\"></a>\n",
    "## Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"systems_firefly\"></a>\n",
    "### [Firefly-RK3399](http://en.t-firefly.com/product/rk3399/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firefly = {\n",
    "    \"division\": \"\",\n",
    "    \"submitter\": \"dividiti\",\n",
    "    \"status\": \"available\",\n",
    "    \"system_name\": \"Firefly-RK3399\",\n",
    "\n",
    "    \"number_of_nodes\": \"1\",\n",
    "    \"host_processor_model_name\": \"Arm Cortex-A72 MP2 (big); Arm Cortex-A53 MP4 (LITTLE)\",\n",
    "    \"host_processors_per_node\": \"1\",\n",
    "    \"host_processor_core_count\": \"2 (big); 4 (LITTLE)\",\n",
    "    \"host_processor_frequency\": \"1800 MHz (big), 1400 MHz (LITTLE)\",\n",
    "    \"host_processor_caches\": \"L1I$ 48 KiB, L1D$ 32 KiB, L2$ 1 MiB (big); L1I$ 32 KiB, L1D$ 32 KiB, L2$ 512 KiB (LITTLE)\",\n",
    "    \"host_memory_configuration\": \"-\",\n",
    "    \"host_memory_capacity\": \"4 GiB\",\n",
    "    \"host_storage_capacity\": \"128 GiB\",\n",
    "    \"host_storage_type\": \"SanDisk Extreme microSD\",\n",
    "    \"host_processor_interconnect\": \"-\",\n",
    "    \"host_networking\": \"-\",\n",
    "    \"host_networking_topology\": \"-\",\n",
    "\n",
    "    \"accelerators_per_node\": \"1\",\n",
    "    \"accelerator_model_name\": \"Arm Mali-T860 MP4\",\n",
    "    \"accelerator_frequency\": \"800 MHz\",\n",
    "    \"accelerator_host_interconnect\": \"-\",\n",
    "    \"accelerator_interconnect\": \"-\",\n",
    "    \"accelerator_interconnect_topology\": \"-\",\n",
    "    \"accelerator_memory_capacity\": \"4 GiB (shared with host)\",\n",
    "    \"accelerator_memory_configuration\": \"-\",\n",
    "    \"accelerator_on-chip_memories\": \"-\",\n",
    "    \"cooling\": \"on-board fan\",\n",
    "    \"hw_notes\": \"http://en.t-firefly.com/product/rk3399/; http://opensource.rock-chips.com/wiki_RK3399\",\n",
    "\n",
    "    \"framework\": \"\",\n",
    "    \"operating_system\": \"Ubuntu 16.04.6 LTS\",\n",
    "    \"other_software_stack\": \"GCC 7.4.0; Python 3.5.2\",\n",
    "    \"sw_notes\": \"Powered by Collective Knowledge v1.11.1\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TFLite v1.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closed_firefly_tflite = deepcopy(firefly)\n",
    "closed_firefly_tflite.update({\n",
    "    \"division\" : \"closed\",\n",
    "    \"framework\" : \"TFLite v1.15.0-rc2\"\n",
    "})\n",
    "closed_firefly_tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_firefly_tflite = deepcopy(firefly)\n",
    "open_firefly_tflite.update({\n",
    "    \"division\" : \"open\",\n",
    "    \"framework\" : \"TFLite v1.15.0-rc2\"\n",
    "})\n",
    "open_firefly_tflite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ArmNN v19.08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closed_firefly_armnn = deepcopy(firefly)\n",
    "closed_firefly_tflite.update({\n",
    "    \"division\" : \"closed\",\n",
    "    \"framework\" : \"ArmNN v19.08\"\n",
    "})\n",
    "closed_firefly_armnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_firefly_armnn = deepcopy(firefly)\n",
    "open_firefly_tflite.update({\n",
    "    \"division\" : \"open\",\n",
    "    \"framework\" : \"ArmNN v19.08\"\n",
    "})\n",
    "open_firefly_armnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"systems_hikey960\"></a>\n",
    "### [Linaro HiKey960](https://www.96boards.org/product/hikey960/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hikey960 = {\n",
    "    \"division\": \"\",\n",
    "    \"submitter\": \"dividiti\",\n",
    "    \"status\": \"available\",\n",
    "    \"system_name\": \"Linaro HiKey960\",\n",
    "\n",
    "    \"number_of_nodes\": \"1\",\n",
    "    \"host_processor_model_name\": \"Arm Cortex-A73 MP4 (big); Arm Cortex-A53 MP4 (LITTLE)\",\n",
    "    \"host_processors_per_node\": \"1\",\n",
    "    \"host_processor_core_count\": \"4 (big); 4 (LITTLE)\",\n",
    "    \"host_processor_frequency\": \"2362 MHz (big), 1844 MHz (LITTLE)\",\n",
    "    \"host_processor_caches\": \"L1I$ 256=4x64 KiB, L1D$ 256=4x64 KiB, L2$ 2 MiB (big); L1I$ 128=4x32 KiB, L1D$ 128=4x32 KiB, L2$ 1 MiB (LITTLE)\",\n",
    "    \"host_memory_configuration\": \"-\",\n",
    "    \"host_memory_capacity\": \"3 GiB\",\n",
    "    \"host_storage_capacity\": \"128 GiB\",\n",
    "    \"host_storage_type\": \"SanDisk Extreme microSD\",\n",
    "    \"host_processor_interconnect\": \"-\",\n",
    "    \"host_networking\": \"-\",\n",
    "    \"host_networking_topology\": \"-\",\n",
    "\n",
    "    \"accelerators_per_node\": \"1\",\n",
    "    \"accelerator_model_name\": \"Arm Mali-G71 MP8\",\n",
    "    \"accelerator_frequency\": \"800 MHz\",\n",
    "    \"accelerator_host_interconnect\": \"-\",\n",
    "    \"accelerator_interconnect\": \"-\",\n",
    "    \"accelerator_interconnect_topology\": \"-\",\n",
    "    \"accelerator_memory_capacity\": \"3 GiB (shared with host)\",\n",
    "    \"accelerator_memory_configuration\": \"-\",\n",
    "    \"accelerator_on-chip_memories\": \"-\",\n",
    "    \"cooling\": \"small external fan\",\n",
    "    \"hw_notes\": \"http://www.hisilicon.com/en/Products/ProductList/Kirin\",\n",
    "\n",
    "    \"framework\": \"\",\n",
    "    \"operating_system\": \"Debian 9\",\n",
    "    \"other_software_stack\": \"GCC 7.4.0; Python 3.5.3\",\n",
    "    \"sw_notes\": \"Powered by Collective Knowledge v1.11.1\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TFLite v1.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closed_hikey960_tflite = deepcopy(hikey960)\n",
    "closed_hikey960_tflite.update({\n",
    "    \"division\" : \"closed\",\n",
    "    \"framework\" : \"TFLite v1.15.0-rc2\"\n",
    "})\n",
    "closed_hikey960_tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_hikey960_tflite = deepcopy(hikey960)\n",
    "open_hikey960_tflite.update({\n",
    "    \"division\" : \"open\",\n",
    "    \"framework\" : \"TFLite v1.15.0-rc2\"\n",
    "})\n",
    "open_hikey960_tflite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ArmNN v19.08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closed_hikey960_armnn = deepcopy(hikey960)\n",
    "closed_hikey960_tflite.update({\n",
    "    \"division\" : \"closed\",\n",
    "    \"framework\" : \"ArmNN v19.08\"\n",
    "})\n",
    "closed_hikey960_armnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_hikey960_armnn = deepcopy(hikey960)\n",
    "open_hikey960_tflite.update({\n",
    "    \"division\" : \"open\",\n",
    "    \"framework\" : \"ArmNN v19.08\"\n",
    "})\n",
    "open_hikey960_armnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"systems_mate10pro\"></a>\n",
    "### Huawei Mate 10 Pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mate10pro = {\n",
    "    \"division\": \"\",\n",
    "    \"submitter\": \"dividiti\",\n",
    "    \"status\": \"available\",\n",
    "    \"system_name\": \"Huawei Mate 10 Pro\",\n",
    "\n",
    "    \"number_of_nodes\": \"1\",\n",
    "    \"host_processor_model_name\": \"Arm Cortex-A73 MP4 (big); Arm Cortex-A53 MP4 (LITTLE)\",\n",
    "    \"host_processors_per_node\": \"1\",\n",
    "    \"host_processor_core_count\": \"4 (big); 4 (LITTLE)\",\n",
    "    \"host_processor_frequency\": \"2360 MHz (big), 1800 MHz (LITTLE)\",\n",
    "    \"host_processor_caches\": \"L1I$ 256=4x64 KiB, L1D$ 256=4x64 KiB, L2$ 2 MiB (big); L1I$ 128=4x32 KiB, L1D$ 128=4x32 KiB, L2$ 1 MiB (LITTLE)\",\n",
    "    \"host_memory_configuration\": \"-\",\n",
    "    \"host_memory_capacity\": \"6 GiB\",\n",
    "    \"host_storage_capacity\": \"128 GiB\",\n",
    "    \"host_storage_type\": \"-\",\n",
    "    \"host_processor_interconnect\": \"-\",\n",
    "    \"host_networking\": \"-\",\n",
    "    \"host_networking_topology\": \"-\",\n",
    "\n",
    "    \"accelerators_per_node\": \"1\",\n",
    "    \"accelerator_model_name\": \"Arm Mali-G72 MP12\",\n",
    "    \"accelerator_frequency\": \"850 MHz\",\n",
    "    \"accelerator_host_interconnect\": \"-\",\n",
    "    \"accelerator_interconnect\": \"-\",\n",
    "    \"accelerator_interconnect_topology\": \"-\",\n",
    "    \"accelerator_memory_capacity\": \"6 GiB (shared with host)\",\n",
    "    \"accelerator_memory_configuration\": \"-\",\n",
    "    \"accelerator_on-chip_memories\": \"-\",\n",
    "    \"cooling\": \"phone case\",\n",
    "    \"hw_notes\": \"https://en.wikichip.org/wiki/hisilicon/kirin/970\",\n",
    "\n",
    "    \"framework\": \"\",\n",
    "    \"operating_system\": \"Android 8\",\n",
    "    \"other_software_stack\": \"Android NDK 17c (LLVM 6.0.2)\",\n",
    "    \"sw_notes\": \"Powered by Collective Knowledge v1.11.1\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TFLite v1.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closed_mate10pro_tflite = deepcopy(mate10pro)\n",
    "closed_mate10pro_tflite.update({\n",
    "    \"division\" : \"closed\",\n",
    "    \"framework\" : \"TFLite v1.13.1\"\n",
    "})\n",
    "closed_mate10pro_tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_mate10pro_tflite = deepcopy(mate10pro)\n",
    "open_mate10pro_tflite.update({\n",
    "    \"division\" : \"open\",\n",
    "    \"framework\" : \"TFLite v1.13.1\"\n",
    "})\n",
    "open_mate10pro_tflite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ArmNN v19.08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closed_mate10pro_armnn = deepcopy(mate10pro)\n",
    "closed_mate10pro_armnn.update({\n",
    "    \"division\" : \"closed\",\n",
    "    \"framework\" : \"ArmNN v19.08\"\n",
    "})\n",
    "closed_mate10pro_armnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_mate10pro_armnn = deepcopy(mate10pro)\n",
    "open_mate10pro_armnn.update({\n",
    "    \"division\" : \"open\",\n",
    "    \"framework\" : \"ArmNN v19.08\"\n",
    "})\n",
    "open_mate10pro_armnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raspberry Pi 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpi4 = {\n",
    "    \"division\": \"\",\n",
    "    \"submitter\": \"dividiti\",\n",
    "    \"status\": \"available\",\n",
    "    \"system_name\": \"Raspberry Pi 4\",\n",
    "\n",
    "    \"number_of_nodes\": \"1\",\n",
    "    \"host_processor_model_name\": \"Arm Cortex-A72 MP4\",\n",
    "    \"host_processors_per_node\": \"1\",\n",
    "    \"host_processor_core_count\": \"4\",\n",
    "    \"host_processor_frequency\": \"1500 MHz\",\n",
    "    \"host_processor_caches\": \"L1I$ 128=4x32 KiB, L1D$ 128=4x32 KiB, L2$ 1 MiB\",\n",
    "    \"host_memory_configuration\": \"-\",\n",
    "    \"host_memory_capacity\": \"4 GiB\",\n",
    "    \"host_storage_capacity\": \"128 GiB\",\n",
    "    \"host_storage_type\": \"SanDisk Extreme Pro microSD\",\n",
    "    \"host_processor_interconnect\": \"-\",\n",
    "    \"host_networking\": \"-\",\n",
    "    \"host_networking_topology\": \"-\",\n",
    "\n",
    "    \"accelerators_per_node\": \"0\",\n",
    "    \"accelerator_model_name\": \"-\",\n",
    "    \"accelerator_frequency\": \"-\",\n",
    "    \"accelerator_host_interconnect\": \"-\",\n",
    "    \"accelerator_interconnect\": \"-\",\n",
    "    \"accelerator_interconnect_topology\": \"-\",\n",
    "    \"accelerator_memory_capacity\": \"-\",\n",
    "    \"accelerator_memory_configuration\": \"-\",\n",
    "    \"accelerator_on-chip_memories\": \"-\",\n",
    "    \"cooling\": \"http://www.raspberrypiwiki.com/index.php/Armor_Case_B\",\n",
    "    \"hw_notes\": \"https://www.raspberrypi.org/products/raspberry-pi-4-model-b/specifications/\",\n",
    "\n",
    "    \"framework\": \"\",\n",
    "    \"operating_system\": \"Debian 10\",\n",
    "    \"other_software_stack\": \"GCC 8.3.0; Python 3.7.3\",\n",
    "    \"sw_notes\": \"Powered by Collective Knowledge v1.11.1\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TFLite v1.15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closed_rpi4_tflite = deepcopy(rpi4)\n",
    "closed_rpi4_tflite.update({\n",
    "    \"division\"  : \"closed\",\n",
    "    \"framework\" : \"TFLite v1.15.0-rc2\"\n",
    "})\n",
    "closed_rpi4_tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_rpi4_tflite = deepcopy(rpi4)\n",
    "open_rpi4_tflite.update({\n",
    "    \"division\"  : \"open\",\n",
    "    \"framework\" : \"TFLite v1.15.0-rc2\"\n",
    "})\n",
    "open_rpi4_tflite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ArmNN v19.08"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closed_rpi4_armnn = deepcopy(rpi4)\n",
    "closed_rpi4_armnn.update({\n",
    "    \"division\"  : \"closed\",\n",
    "    \"framework\" : \"ArmNN v19.08\"\n",
    "})\n",
    "closed_rpi4_armnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_rpi4_armnn = deepcopy(rpi4)\n",
    "open_rpi4_armnn.update({\n",
    "    \"division\"  : \"open\",\n",
    "    \"framework\" : \"ArmNN v19.08\"\n",
    "})\n",
    "open_rpi4_armnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "division_systems = {\n",
    "    # Closed.\n",
    "    'closed-firefly-tflite-v1.15'   : closed_firefly_tflite,\n",
    "    'closed-firefly-armnn-v19.08'   : closed_firefly_armnn,\n",
    "    'closed-hikey960-tflite-v1.15'  : closed_hikey960_tflite,\n",
    "    'closed-hikey960-armnn-v19.08'  : closed_hikey960_armnn,\n",
    "    'closed-mate10pro-tflite-v1.13' : closed_mate10pro_tflite,\n",
    "    'closed-mate10pro-armnn-v19.08' : closed_mate10pro_armnn,\n",
    "    'closed-rpi4-tflite-v1.15'      : closed_rpi4_tflite,\n",
    "    'closed-rpi4-armnn-v19.08'      : closed_rpi4_armnn,    \n",
    "    # Open.\n",
    "    'open-firefly-tflite-v1.15'     : open_firefly_tflite,\n",
    "    'open-firefly-armnn-v19.08'     : open_firefly_armnn,\n",
    "    'open-hikey960-tflite-v1.15'    : open_hikey960_tflite,\n",
    "    'open-hikey960-armnn-v19.08'    : open_hikey960_armnn,\n",
    "    'open-mate10pro-tflite-v1.13'   : open_mate10pro_tflite,\n",
    "    'open-mate10pro-armnn-v19.08'   : open_mate10pro_armnn,\n",
    "    'open-rpi4-tflite-v1.15'        : open_rpi4_tflite,\n",
    "    'open-rpi4-armnn-v19.08'        : open_rpi4_armnn,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default `system_desc_id.json` (to catch uninitialized descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_system_json = {\n",
    "    \"division\": \"reqired\",\n",
    "    \"submitter\": \"required\",\n",
    "    \"status\": \"required\",\n",
    "    \"system_name\": \"required\",\n",
    "\n",
    "    \"number_of_nodes\": \"required\",\n",
    "    \"host_processor_model_name\": \"required\",\n",
    "    \"host_processors_per_node\": \"required\",\n",
    "    \"host_processor_core_count\": \"required\",\n",
    "    \"host_processor_frequency\": \"\",\n",
    "    \"host_processor_caches\": \"\",\n",
    "    \"host_memory_configuration\": \"\",\n",
    "    \"host_memory_capacity\": \"required\",\n",
    "    \"host_storage_capacity\": \"required\",\n",
    "    \"host_storage_type\": \"required\",\n",
    "    \"host_processor_interconnect\": \"\",\n",
    "    \"host_networking\": \"\",\n",
    "    \"host_networking_topology\": \"\",\n",
    "\n",
    "    \"accelerators_per_node\": \"required\",\n",
    "    \"accelerator_model_name\": \"required\",\n",
    "    \"accelerator_frequency\": \"\",\n",
    "    \"accelerator_host_interconnect\": \"\",\n",
    "    \"accelerator_interconnect\": \"\",\n",
    "    \"accelerator_interconnect_topology\": \"\",\n",
    "    \"accelerator_memory_capacity\": \"required\",\n",
    "    \"accelerator_memory_configuration\": \"\",\n",
    "    \"accelerator_on-chip_memories\": \"\",\n",
    "    \"cooling\": \"\",\n",
    "    \"hw_notes\": \"\",\n",
    "\n",
    "    \"framework\": \"required\",\n",
    "    \"operating_system\": \"required\",\n",
    "    \"other_software_stack\": \"required\",\n",
    "    \"sw_notes\": \"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"implementations\"></a>\n",
    "## Implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate implementation_benchmarks dictionary.\n",
    "implementation_benchmarks = {}\n",
    "\n",
    "for implementation in [ 'image-classification-tflite', 'image-classification-armnn-tflite' ]:\n",
    "    # Add MobileNet.\n",
    "    implementation_mobilenet = implementation+'-'+'mobilenet'\n",
    "    implementation_benchmarks[implementation_mobilenet] = {\n",
    "        \"input_data_types\": \"fp32\",\n",
    "        \"weight_data_types\": \"fp32\",\n",
    "        \"retraining\": \"no\",\n",
    "        \"starting_weights_filename\": \"https://zenodo.org/record/2269307/files/mobilenet_v1_1.0_224.tgz\",\n",
    "        \"weight_transformations\": \"TFLite\"\n",
    "    }\n",
    "    # Add ResNet.\n",
    "    implementation_resnet = implementation+'-'+'resnet'\n",
    "    implementation_benchmarks[implementation_resnet] = {\n",
    "        \"input_data_types\": \"fp32\",\n",
    "        \"weight_data_types\": \"fp32\",\n",
    "        \"retraining\": \"no\",\n",
    "        \"starting_weights_filename\": \"https://zenodo.org/record/2535873/files/resnet50_v1.pb\",\n",
    "        \"weight_transformations\": \"TF -> TFLite\"\n",
    "    }\n",
    "    # Add any MobileNets-v1,v2 model.\n",
    "    def add_implementation_mobilenet(implementation_benchmarks, version, multiplier, resolution):\n",
    "        base_url = 'https://zenodo.org/record/2269307/files' if version == 1 else 'https://zenodo.org/record/2266646/files'\n",
    "        url = '{}/mobilenet_v{}_{}_{}.tgz'.format(base_url, version, multiplier, resolution)\n",
    "        benchmark = 'mobilenet-v{}-{}-{}'.format(version, multiplier, resolution)\n",
    "        if implementation == 'image-classification-tflite':\n",
    "            weights_transformations = 'TFLite'\n",
    "        elif implementation == 'image-classification-armnn-tflite':\n",
    "            weights_transformations = 'TFLite -> ArmNN'\n",
    "        else:\n",
    "            raise \"Unknown implementation '%s'!\" % implementation\n",
    "        implementation_benchmark = implementation+'-'+benchmark\n",
    "        implementation_benchmarks[implementation_benchmark] = {\n",
    "            \"input_data_types\": \"fp32\",\n",
    "            \"weight_data_types\": \"fp32\",\n",
    "            \"retraining\": \"no\",\n",
    "            \"starting_weights_filename\": url,\n",
    "            \"weight_transformations\": weights_transformations\n",
    "        }\n",
    "        return\n",
    "    # MobileNet-v1.\n",
    "    version = 1\n",
    "    for multiplier in [ 1.0, 0.75, 0.5, 0.25 ]:\n",
    "        for resolution in [ 224, 192, 160, 128 ]:\n",
    "            add_implementation_mobilenet(implementation_benchmarks, version, multiplier, resolution)\n",
    "    # MobileNet-v2.\n",
    "    version = 2\n",
    "    for multiplier in [ 1.0, 0.75, 0.5, 0.35 ]:\n",
    "        for resolution in [ 224, 192, 160, 128, 96 ]:\n",
    "            add_implementation_mobilenet(implementation_benchmarks, version, multiplier, resolution)\n",
    "    add_implementation_mobilenet(implementation_benchmarks, version=2, multiplier=1.3, resolution=224)\n",
    "    add_implementation_mobilenet(implementation_benchmarks, version=2, multiplier=1.4, resolution=224)\n",
    "\n",
    "# from pprint import pprint\n",
    "# pprint(implementation_benchmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "implementation_readmes = {}\n",
    "implementation_readmes['image-classification-tflite'] = \\\n",
    "\"\"\"# MLPerf Inference - Image Clasification - TFLite\n",
    "- [Source code](https://github.com/ctuning/ck-mlperf/tree/master/program/image-classification-tflite-loadgen).\n",
    "- [Instructions](https://github.com/mlperf/inference/blob/master/v0.5/classification_and_detection/optional_harness_ck/classification/tflite/README.md).\n",
    "\"\"\"\n",
    "\n",
    "implementation_readmes['image-classification-armnn-tflite'] = \\\n",
    "\"\"\"# MLPerf Inference - Image Clasification - ArmNN-TFLite\n",
    "- [Source code](https://github.com/ctuning/ck-mlperf/tree/master/program/image-classification-armnn-tflite-loadgen).\n",
    "- [Instructions](https://github.com/ARM-software/armnn-mlperf/blob/master/README.md).\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "implementation_paths = {}\n",
    "for implementation in [ 'image-classification-tflite', 'image-classification-armnn-tflite' ]:\n",
    "    implementation_loadgen = implementation+'-loadgen'\n",
    "    r = ck.access({'action':'find', 'repo_uoa':'ck-mlperf', 'module_uoa':'program', 'data_uoa':implementation_loadgen})\n",
    "    if r['return']>0:\n",
    "        print('Error: %s' % r['error'])\n",
    "        exit(1)\n",
    "    implementation_paths[implementation] = r['path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snapshot of https://github.com/dividiti/inference/blob/61220457dec221ed1984c62bd9d382698bd71bc6/v0.5/mlperf.conf\n",
    "mlperf_conf_6122045 = '''\n",
    "# The format of this config file is 'key = value'.\n",
    "# The key has the format 'model.scenario.key'. Value is mostly int64_t.\n",
    "# Model maybe '*' as wildcard. In that case the value applies to all models.\n",
    "# All times are in milli seconds\n",
    "\n",
    "*.SingleStream.target_latency = 10\n",
    "*.SingleStream.target_latency_percentile = 90\n",
    "*.SingleStream.min_duration = 60000\n",
    "*.SingleStream.min_query_count = 1024\n",
    "\n",
    "*.MultiStream.target_qps = 20\n",
    "*.MultiStream.target_latency_percentile = 99\n",
    "*.MultiStream.samples_per_query = 4\n",
    "*.MultiStream.max_async_queries = 1\n",
    "*.MultiStream.target_latency = 50\n",
    "*.MultiStream.min_duration = 60000\n",
    "*.MultiStream.min_query_count = 270336\n",
    "ssd-resnet34.MultiStream.target_qps = 15\n",
    "ssd-resnet34.MultiStream.target_latency = 66\n",
    "gnmt.MultiStream.min_query_count = 90112\n",
    "gnmt.MultiStream.target_latency = 100\n",
    "gnmt.MultiStream.target_qps = 10\n",
    "gnmt.MultiStream.target_latency_percentile = 97\n",
    "\n",
    "*.Server.target_qps = 1.0\n",
    "*.Server.target_latency = 10\n",
    "*.Server.target_latency_percentile = 99\n",
    "*.Server.target_duration = 0\n",
    "*.Server.min_duration = 60000\n",
    "*.Server.min_query_count = 270336\n",
    "resnet50.Server.target_latency = 15\n",
    "ssd-resnet34.Server.target_latency = 100\n",
    "gnmt.Server.min_query_count = 90112\n",
    "gnmt.Server.target_latency = 250\n",
    "gnmt.Server.target_latency_percentile = 97\n",
    "\n",
    "*.Offline.target_qps = 1.0\n",
    "*.Offline.target_latency_percentile = 90\n",
    "*.Offline.min_duration = 60000\n",
    "*.Offline.min_query_count = 1\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Default `system_desc_id_imp.json` (to catch uninitialized descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_implementation_benchmark_json = {\n",
    "    \"input_data_types\": \"required\",\n",
    "    \"retraining\": \"required\",\n",
    "    \"starting_weights_filename\": \"required\",\n",
    "    \"weight_data_types\": \"required\",\n",
    "    \"weight_transformations\": \"required\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"get\"></a>\n",
    "## Get the experimental data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download experimental data and add CK repositories as follows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Classification - Closed (MobileNet, ResNet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `firefly`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "$ wget https://www.dropbox.com/s/3md826fk7k1taf3/mlperf.closed.image-classification.firefly.tflite-v1.15.zip\n",
    "$ ck add repo --zip=mlperf.closed.image-classification.firefly.tflite-v1.15.zip\n",
    "\n",
    "$ https://www.dropbox.com/s/jusoz329mhixpxm/mlperf.closed.image-classification.firefly.armnn-v19.08.neon.zip\n",
    "$ ck add repo --zip=mlperf.closed.image-classification.firefly.armnn-v19.08.neon.zip\n",
    "\n",
    "$ wget https://www.dropbox.com/s/08lzbz7jl2w5jhu/mlperf.closed.image-classification.firefly.armnn-v19.08.opencl.zip\n",
    "$ ck add repo --zip=mlperf.closed.image-classification.firefly.armnn-v19.08.opencl.zip\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `hikey960`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "$ wget https://www.dropbox.com/s/lqnffl6wbaeceul/mlperf.closed.image-classification.hikey960.tflite-v1.15.zip\n",
    "$ ck add repo --zip=mlperf.closed.image-classification.hikey960.tflite-v1.15.zip\n",
    "\n",
    "$ wget https://www.dropbox.com/s/6m6uv1d33yc82f8/mlperf.closed.image-classification.hikey960.armnn-v19.08.neon.zip\n",
    "$ ck add repo --zip=mlperf.closed.image-classification.hikey960.armnn-v19.08.neon.zip\n",
    "\n",
    "$ wget https://www.dropbox.com/s/bz56y4damfqggr8/mlperf.closed.image-classification.hikey960.armnn-v19.08.opencl.zip\n",
    "$ ck add repo --zip=mlperf.closed.image-classification.hikey960.armnn-v19.08.opencl.zip\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `rpi4`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: missing performance experiments with TFLite v1.15; no experiments with ArmNN v19.08 with Neon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `mate10pro` (**BAD LOADGEN**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "$ wget https://www.dropbox.com/s/nts8e7unb7vm68f/mlperf.closed.image-classification.mate10pro.tflite-v1.13.mobilenet.zip\n",
    "$ ck add repo --zip=mlperf.closed.image-classification.mate10pro.tflite-v1.13.mobilenet.zip\n",
    "\n",
    "$ wget https://www.dropbox.com/s/t2o2elqdyitqlpi/mlperf.closed.image-classification.mate10pro.armnn-v19.08.neon.zip\n",
    "$ ck add repo --zip=mlperf.closed.image-classification.mate10pro.armnn-v19.08.neon.zip\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:** accuracy experiment with TFLite v1.15 for ResNet aborted (estimated 17 hours); no OpenCL experiments with ArmNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Classification - Open (MobileNets-v1,v2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `firefly`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "$ wget https://www.dropbox.com/s/q8ieqgnr3zn6w4y/mlperf.open.image-classification.firefly.tflite-v1.15.zip\n",
    "$ ck add repo --zip=mlperf.open.image-classification.firefly.tflite-v1.15.zip\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:** experiments with ArmNN  w/ OpenCL are in progress."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `hikey960`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "$ wget https://www.dropbox.com/s/2gbbpsd2pjurvc8/mlperf.open.image-classification.hikey960.tflite-v1.15.zip\n",
    "$ ck add repo --zip=mlperf.open.image-classification.hikey960.tflite-v1.15.zip\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:** experiments with ArmNN  w/ OpenCL are in progress."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `rpi4`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:** experiments with TFLite are in progress."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"check\"></a>\n",
    "## Check the experimental data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repos = [\n",
    "    #\n",
    "    # Image Classification - Closed (MobileNet, ResNet)\n",
    "    #\n",
    "    # firefly\n",
    "    'mlperf.closed.image-classification.firefly.tflite-v1.15',\n",
    "    'mlperf.closed.image-classification.firefly.armnn-v19.08.neon',\n",
    "    'mlperf.closed.image-classification.firefly.armnn-v19.08.opencl',\n",
    "    # hikey960\n",
    "    'mlperf.closed.image-classification.hikey960.tflite-v1.15',\n",
    "    'mlperf.closed.image-classification.hikey960.armnn-v19.08.neon',\n",
    "    'mlperf.closed.image-classification.hikey960.armnn-v19.08.opencl',\n",
    "    # mate10pro\n",
    "    'mlperf.closed.image-classification.mate10pro.armnn-v19.08.neon', # BAD LOADGEN\n",
    "    'mlperf.closed.image-classification.mate10pro.tflite-v1.13.mobilenet', # BAD LOADGEN\n",
    "    # Image Classification - Open (MobileNets-v1,v2)\n",
    "    # firefly\n",
    "    'mlperf.open.image-classification.firefly.tflite-v1.15',\n",
    "    # hikey960\n",
    "    'mlperf.open.image-classification.hikey960.tflite-v1.15',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ck recache repo\n",
    "for repo_uoa in repos:\n",
    "    print(\"=\" * 100)\n",
    "    print(repo_uoa)\n",
    "    print(\"=\" * 100)\n",
    "    !ck list $repo_uoa:experiment:* | sort\n",
    "    print(\"-\" * 100)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate upstream master.\n",
    "r = ck.access({'action':'locate', 'module_uoa':'env', 'tags':'mlperf,inference,source,upstream.master'})\n",
    "if r['return']>0:\n",
    "    print('Error: %s' % r['error'])\n",
    "    exit(1)\n",
    "# Pick any source location and look under 'inference/v0.5/mlperf.conf'.\n",
    "upstream_path = os.path.join(list(r['install_locations'].values())[0], 'inference')\n",
    "upstream_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_experimental_results(repo_uoa, module_uoa='experiment', tags='mlperf', submitter='dividiti', path=None):\n",
    "    if not path:\n",
    "        path_list = !ck find repo:$repo_uoa\n",
    "        path = path_list[0]\n",
    "    root_dir = os.path.join(path, 'submissions_inference_0_5')\n",
    "    if not os.path.exists(root_dir): os.mkdir(root_dir)\n",
    "    print(\"Storing results under '%s'\" % root_dir)\n",
    "    \n",
    "    r = ck.access({'action':'search', 'repo_uoa':repo_uoa, 'module_uoa':module_uoa, 'tags':tags})\n",
    "    if r['return']>0:\n",
    "        print('Error: %s' % r['error'])\n",
    "        exit(1)\n",
    "    experiments = r['lst']\n",
    "\n",
    "    dfs = []\n",
    "    for experiment in experiments:\n",
    "        data_uoa = experiment['data_uoa']\n",
    "        r = ck.access({'action':'list_points', 'repo_uoa':repo_uoa, 'module_uoa':module_uoa, 'data_uoa':data_uoa})\n",
    "        if r['return']>0:\n",
    "            print('Error: %s' % r['error'])\n",
    "            exit(1)\n",
    "        print(\"*\" * 100)\n",
    "\n",
    "        tags = r['dict']['tags']\n",
    "        #print(tags)\n",
    "        if 'accuracy' in tags:\n",
    "            if 'neon' in tags or 'opencl' in tags:\n",
    "                # Expected format: [ \"mlperf\", \"open\", \"image-classification\", \"firefly\", \"armnn-v19.08\", \"neon\", \"mobilenet-v1-0.5-128\", \"singlestream\", \"accuracy\", \"using-opencv\" ]\n",
    "                (_, division, task, platform, library, backend, benchmark, scenario, mode, preprocessing) = tags\n",
    "            else:\n",
    "                # Expected format: [ \"mlperf\", \"open\", \"image-classification\", \"firefly\", \"tflite-v1.15\", \"mobilenet-v1-0.5-128\", \"singlestream\", \"accuracy\", \"using-opencv\" ]\n",
    "                (_, division, task, platform, library, benchmark, scenario, mode, preprocessing) = tags\n",
    "        elif 'performance' in tags:            \n",
    "            if 'neon' in tags or 'opencl' in tags:\n",
    "                # Expected format: [ \"mlperf\", \"open\", \"image-classification\", \"firefly\", \"armnn-v19.08\", \"neon\", \"mobilenet-v1-0.5-128\", \"singlestream\", \"performance\" ]\n",
    "                (_, division, task, platform, library, backend, benchmark, scenario, mode) = tags\n",
    "            else:\n",
    "                # Expected format: [ \"mlperf\", \"open\", \"image-classification\", \"firefly\", \"tflite-v1.15\", \"mobilenet-v1-0.5-128\", \"singlestream\", \"performance\" ]\n",
    "                (_, division, task, platform, library, benchmark, scenario, mode) = tags\n",
    "        else:\n",
    "            raise \"Expected 'accuracy' or 'performance' in tags!\"\n",
    "            \n",
    "        organization = submitter\n",
    "        system = platform+'-'+library\n",
    "        division_system = division+'-'+system\n",
    "        if library.startswith('tflite'):\n",
    "            implementation = task+'-tflite'\n",
    "        elif library.startswith('armnn'):\n",
    "            implementation = task+'-armnn-tflite'\n",
    "        else: # Official app with CK adaptations.\n",
    "            implementation = 'mlperf-inference-vision'\n",
    "        implementation_benchmark = implementation+'-'+benchmark\n",
    "        \n",
    "        #\n",
    "        # Directory structure according to the Inference section of the General MLPerf Submission Rules:\n",
    "        # https://github.com/mlperf/policies/blob/master/submission_rules.adoc#552-inference\n",
    "        #\n",
    "        # <division>/\n",
    "        #   <organization>/\n",
    "        #\n",
    "        division_dir = os.path.join(root_dir, division)\n",
    "        if not os.path.exists(division_dir): os.mkdir(division_dir)\n",
    "        organization_dir = os.path.join(division_dir, organization)\n",
    "        if not os.path.exists(organization_dir): os.mkdir(organization_dir)\n",
    "        \n",
    "        #\n",
    "        #     \"systems\"/\n",
    "        #       <system_desc_id>.json\n",
    "        #\n",
    "        systems_dir = os.path.join(organization_dir, 'systems')\n",
    "        if not os.path.exists(systems_dir): os.mkdir(systems_dir)\n",
    "        system_json_name = '%s.json' % system\n",
    "        system_json_path = os.path.join(systems_dir, system_json_name)\n",
    "        with open(system_json_path, 'w') as system_json_file:\n",
    "#             pprint(division_system)\n",
    "#             pprint(division_systems)\n",
    "            system_json = division_systems.get(division_system, default_system_json)\n",
    "            json.dump(system_json, system_json_file, indent=2)\n",
    "            print('%s' % systems_dir)\n",
    "            if system_json == default_system_json:\n",
    "                print('  |_ %s [DEFAULT]' % system_json_name)\n",
    "                raise\n",
    "            else:\n",
    "                print('  |_ %s [%s]' % (system_json_name, division_system))\n",
    "        \n",
    "        #\n",
    "        #     \"code\"/\n",
    "        #       <benchmark_name_per_reference>/\n",
    "        #         <implementation_id>/\n",
    "        #           <Code interface with loadgen and other arbitrary stuff>\n",
    "        #\n",
    "        code_dir = os.path.join(organization_dir, 'code')\n",
    "        if not os.path.exists(code_dir): os.mkdir(code_dir)\n",
    "        # FIXME: For now, not always \"per reference\".\n",
    "        benchmark_dir = os.path.join(code_dir, benchmark)\n",
    "        if not os.path.exists(benchmark_dir): os.mkdir(benchmark_dir)\n",
    "        implementation_dir = os.path.join(benchmark_dir, implementation)\n",
    "        if not os.path.exists(implementation_dir): os.mkdir(implementation_dir)\n",
    "        print('%s' % code_dir)\n",
    "        # Create 'README.md'.\n",
    "        implementation_readme_name = 'README.md'\n",
    "        implementation_readme_path = os.path.join(implementation_dir, implementation_readme_name)\n",
    "        implementation_readme = implementation_readmes.get(implementation, '')\n",
    "#         pprint(implementation)\n",
    "#         pprint(implementation_readmes)\n",
    "        with open(implementation_readme_path, 'w') as implementation_readme_file:\n",
    "            implementation_readme_file.writelines(implementation_readme)\n",
    "        if implementation_readme == '':\n",
    "            print('  |_ %s [EMPTY]' % implementation_readme_name)\n",
    "            raise\n",
    "        else:\n",
    "            print('  |_ %s' % implementation_readme_name)\n",
    "        # TODO: Copy run.sh\n",
    "\n",
    "        #\n",
    "        #     \"measurements\"/\n",
    "        #       <system_desc_id>/\n",
    "        #         <benchmark>/\n",
    "        #           <scenario>/\n",
    "        #             <system_desc_id>_<implementation_id>.json\n",
    "        #             README.md\n",
    "        #             user.conf\n",
    "        #             mlperf.conf\n",
    "        #             calibration_process.adoc (?)\n",
    "        #\n",
    "        measurements_dir = os.path.join(organization_dir, 'measurements')\n",
    "        if not os.path.exists(measurements_dir): os.mkdir(measurements_dir)\n",
    "        system_dir = os.path.join(measurements_dir, system)\n",
    "        if not os.path.exists(system_dir): os.mkdir(system_dir)\n",
    "        benchmark_dir = os.path.join(system_dir, benchmark)\n",
    "        if not os.path.exists(benchmark_dir): os.mkdir(benchmark_dir)\n",
    "        scenario_dir = os.path.join(benchmark_dir, scenario)\n",
    "        if not os.path.exists(scenario_dir): os.mkdir(scenario_dir)\n",
    "        print(scenario_dir)\n",
    "        # Create '<system_desc_id>_<implementation_id>.json'.\n",
    "        system_implementation_json_name = system+'_'+implementation+'.json'\n",
    "        system_implementation_json_path = os.path.join(scenario_dir, system_implementation_json_name)\n",
    "        with open(system_implementation_json_path, 'w') as system_implementation_json_file:\n",
    "#             pprint(implementation_benchmark)\n",
    "#             pprint(implementation_benchmarks)\n",
    "            implementation_benchmark_json = implementation_benchmarks.get(implementation_benchmark, default_implementation_benchmark_json)\n",
    "            json.dump(implementation_benchmark_json, system_implementation_json_file, indent=2)\n",
    "            if implementation_benchmark_json == default_implementation_benchmark_json:\n",
    "                print('  |_ %s [DEFAULT]' % system_implementation_json_name)\n",
    "                raise\n",
    "            else:\n",
    "                print('  |_ %s [%s]' % (system_implementation_json_name, implementation_benchmark))\n",
    "        # Create empty 'README.md'.\n",
    "        system_implementation_readme_name = 'README.md'\n",
    "        system_implementation_readme_path = os.path.join(scenario_dir, system_implementation_readme_name)\n",
    "        with open(system_implementation_readme_path, 'a'):\n",
    "            os.utime(system_implementation_readme_path, None)\n",
    "            print('  |_ %s [EMPTY]' % system_implementation_readme_name)\n",
    "        \n",
    "        # Copy 'user.conf' from the implementation source.\n",
    "        user_conf_name = 'user.conf'\n",
    "        implementation_path = implementation_paths.get(implementation, '')\n",
    "        if implementation_path == '':\n",
    "            raise \"Invalid implementation path!\"\n",
    "        else:\n",
    "            user_conf_path = os.path.join(implementation_path, user_conf_name)\n",
    "            copy2(user_conf_path, scenario_dir)\n",
    "            print('  |_ %s [from %s]' % (user_conf_name, user_conf_path))\n",
    "        \n",
    "        # Copy 'mlperf.conf' from MLPerf Inference source.\n",
    "        mlperf_conf_name = 'mlperf.conf'\n",
    "        mlperf_conf_path = os.path.join(scenario_dir, mlperf_conf_name)\n",
    "        if implementation in [ 'image-classification-tflite', 'image-classification-armnn-tflite' ]:\n",
    "            # Write a snapshot from https://github.com/dividiti/inference/blob/61220457dec221ed1984c62bd9d382698bd71bc6/v0.5/mlperf.conf\n",
    "            with open(mlperf_conf_path, 'w') as mlperf_conf_file:\n",
    "                mlperf_conf_file.writelines(mlperf_conf_6122045)\n",
    "            print('  |_ %s [from %s]' % (mlperf_conf_name, 'github.com/mlperf/inference@6122045'))\n",
    "        else:\n",
    "            upstream_mlperf_conf_path = os.path.join(upstream_path, 'v0.5', 'mlperf.conf')\n",
    "            copy2(upstream_mlperf_conf_path, mlperf_conf_path)\n",
    "            print('  |_ %s [from %s]' % (mlperf_conf_name, upstream_mlperf_conf_path))\n",
    "        \n",
    "        #\n",
    "        #     \"results\"/\n",
    "        #       <system_desc_id>/\n",
    "        #         <benchmark>/\n",
    "        #           <scenario>/\n",
    "        #             performance/\n",
    "        #               run_x/ # 1 run for single stream and offline, 5 otherwise\n",
    "        #                 mlperf_log_summary.txt\n",
    "        #                 mlperf_log_detail.txt\n",
    "        #                 mlperf_log_trace.json\n",
    "        #             accuracy/\n",
    "        #               mlperf_log_accuracy.json\n",
    "        #       compliance_checker_log.txt (?)\n",
    "        #\n",
    "        results_dir = os.path.join(organization_dir, 'results')\n",
    "        if not os.path.exists(results_dir): os.mkdir(results_dir)\n",
    "        system_dir = os.path.join(results_dir, system)\n",
    "        if not os.path.exists(system_dir): os.mkdir(system_dir)\n",
    "        benchmark_dir = os.path.join(system_dir, benchmark)\n",
    "        if not os.path.exists(benchmark_dir): os.mkdir(benchmark_dir)\n",
    "        scenario_dir = os.path.join(benchmark_dir, scenario)\n",
    "        if not os.path.exists(scenario_dir): os.mkdir(scenario_dir)\n",
    "        mode_dir = os.path.join(scenario_dir, mode)\n",
    "        if not os.path.exists(mode_dir): os.mkdir(mode_dir)\n",
    "        # For each point (should be one point for each performance run).\n",
    "        points = r['points']\n",
    "        for (point, point_idx) in zip(points, range(1,len(points)+1)):\n",
    "            point_file_path = os.path.join(r['path'], 'ckp-%s.0001.json' % point)\n",
    "            with open(point_file_path) as point_file:\n",
    "                point_data_raw = json.load(point_file)\n",
    "            characteristics_list = point_data_raw['characteristics_list']\n",
    "            characteristics = characteristics_list[0]\n",
    "            # Set the leaf directory.\n",
    "            if mode == 'performance':\n",
    "                run_dir = os.path.join(mode_dir, 'run_%d' % point_idx)\n",
    "                if not os.path.exists(run_dir): os.mkdir(run_dir)\n",
    "                last_dir = run_dir\n",
    "            else:\n",
    "                last_dir = mode_dir\n",
    "            print(last_dir)\n",
    "            # Dump files in the leaf directory.\n",
    "            mlperf_log = characteristics['run'].get('mlperf_log',{})\n",
    "            # Summary file (with errors and warnings in accuracy mode, with statistics in performance mode).\n",
    "            summary_txt_name = 'mlperf_log_summary.txt'\n",
    "            summary_txt_path = os.path.join(last_dir, summary_txt_name)\n",
    "            with open(summary_txt_path, 'w') as summary_txt_file:\n",
    "                summary_txt_file.writelines(mlperf_log.get('summary',''))\n",
    "                print('  |_ %s' % summary_txt_name)\n",
    "            # Detail file (with settings).\n",
    "            detail_txt_name = 'mlperf_log_detail.txt'\n",
    "            detail_txt_path = os.path.join(last_dir, detail_txt_name)\n",
    "            with open(detail_txt_path, 'w') as detail_txt_file:\n",
    "                detail_txt_file.writelines(mlperf_log.get('detail',''))\n",
    "                print('  |_ %s' % detail_txt_name)\n",
    "            # Accuracy file (with accuracy dictionary).\n",
    "            # FIXME: Move the next 5 lines into the (if mode == 'accuracy') block,\n",
    "            # once the submission checker no longer complains as follows:\n",
    "            # \"performance/run_1 has file list mismatch (['mlperf_log_accuracy.json'])\"\n",
    "            accuracy_json_name = 'mlperf_log_accuracy.json'\n",
    "            accuracy_json_path = os.path.join(last_dir, accuracy_json_name)\n",
    "            with open(accuracy_json_path, 'w') as accuracy_json_file:\n",
    "                json.dump(mlperf_log.get('accuracy',{}), accuracy_json_file, indent=2)\n",
    "                print('  |_ %s' % accuracy_json_name)\n",
    "            if mode == 'accuracy':\n",
    "                accuracy_imagenet_py = os.path.join(upstream_path, 'v0.5', 'classification_and_detection', 'tools', 'accuracy-imagenet.py')\n",
    "                imagenet_val_file = '$HOME/CK_TOOLS/dataset-imagenet-ilsvrc2012-aux/val.txt' # FIXME: Do not hardcode - locate via CK.\n",
    "                accuracy_txt_name = 'accuracy.txt'\n",
    "                accuracy_txt_path = os.path.join(last_dir, accuracy_txt_name)\n",
    "                accuracy_txt = !python3 $accuracy_imagenet_py --imagenet-val-file $imagenet_val_file --mlperf-accuracy-file $accuracy_json_path\n",
    "                with open(accuracy_txt_path, 'w') as accuracy_txt_file:\n",
    "                    accuracy_txt_file.writelines(accuracy_txt)\n",
    "                    # Print the first line containing accuracy info.\n",
    "                    print('  |_ %s [\"%s\"]' % (accuracy_txt_name, accuracy_txt[0]))\n",
    "#             # Trace file (should omit trace from v0.5).\n",
    "#             trace_json_name = 'mlperf_log_trace.json'\n",
    "#             trace_json_path = os.path.join(last_dir, trace_json_name)\n",
    "#             with open(trace_json_path, 'w') as trace_json_file:\n",
    "#                 json.dump(mlperf_log.get('trace',{}), trace_json_file, indent=2)\n",
    "\n",
    "    print(\"*\" * 100)\n",
    "    submission_checker_py = os.path.join(upstream_path, 'v0.5', 'tools', 'submission', 'submission-checker.py')\n",
    "    checker_log = !python3 $submission_checker_py --input $root_dir --submitter $submitter\n",
    "    checker_log = \"\\n\".join(checker_log)\n",
    "    print(checker_log)\n",
    "    checker_log_name = 'compliance_checker_log.txt'\n",
    "    checker_log_path = os.path.join(organization_dir, checker_log_name)\n",
    "    with open(checker_log_path, 'w') as checker_log_file:\n",
    "        checker_log_file.writelines(checker_log)\n",
    "        print(organization_dir)\n",
    "        print('  |_%s' % checker_log_name)\n",
    "    \n",
    "    return dfs\n",
    "\n",
    "repo_uoa = 'mlperf.open.image-classification.firefly.tflite-v1.15'\n",
    "dfs = get_experimental_results(repo_uoa)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
