{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [dividiti](http://dividiti.com)'s submissions to [MLPerf Inference v0.5](https://github.com/mlperf/inference/tree/master/v0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"overview\"></a>\n",
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter notebook covers [dividiti](http://dividiti.com)'s submissions to [MLPerf Inference v0.5](https://github.com/mlperf/inference/tree/master/v0.5). It validates that experimental data obtained via automated, portable and reproducible [Collective Knowledge](http://cknowledge.org) workflows conforms to [General MLPerf Submission Rules](https://github.com/mlperf/policies/blob/master/submission_rules.adoc)\n",
    "and [MLPerf Inference Rules](https://github.com/mlperf/inference_policies/blob/master/inference_rules.adoc), including runnning the official [`submission_checker.py`](https://github.com/mlperf/inference/blob/master/v0.5/tools/submission/submission-checker.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [Overview](#overview)\n",
    "1. [Includes](#includes)\n",
    "1. [Systems](#systems)\n",
    "  1. [Firefly-RK3399](#systems_firefly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"includes\"></a>\n",
    "## Includes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import re\n",
    "\n",
    "from copy import deepcopy\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scientific"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If some of the scientific packages are missing, please install them using:\n",
    "```\n",
    "# python3 -m pip install jupyter pandas numpy matplotlib seaborn --user\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython as ip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mp\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('IPython version: %s' % ip.__version__)\n",
    "print ('Pandas version: %s' % pd.__version__)\n",
    "print ('NumPy version: %s' % np.__version__)\n",
    "print ('Matplotlib version: %s' % mp.__version__)\n",
    "print ('Seaborn version: %s' % sb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "def display_in_full(df):\n",
    "    pd.options.display.max_columns = len(df.columns)\n",
    "    pd.options.display.max_rows = len(df.index)\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_colormap = cm.autumn\n",
    "default_fontsize = 16\n",
    "default_barwidth = 0.8\n",
    "default_figwidth = 24\n",
    "default_figheight = 3\n",
    "default_figdpi = 200\n",
    "default_figsize = [default_figwidth, default_figheight]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mp.__version__[0]=='2': mp.style.use('classic')\n",
    "mp.rcParams['figure.max_open_warning'] = 200\n",
    "mp.rcParams['figure.dpi'] = default_figdpi\n",
    "mp.rcParams['font.size'] = default_fontsize\n",
    "mp.rcParams['legend.fontsize'] = 'medium'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fig_dir = os.path.join(os.path.expanduser(\"~\"), 'mlperf-dividiti')\n",
    "if not os.path.exists(save_fig_dir):\n",
    "    os.mkdir(save_fig_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collective Knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If CK is not installed, please install it using:\n",
    "```\n",
    "# python -m pip install ck\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ck.kernel as ck\n",
    "print ('CK version: %s' % ck.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"systems\"></a>\n",
    "## Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"systems_firefly\"></a>\n",
    "### [Firefly-RK3399](http://en.t-firefly.com/product/rk3399/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "firefly = {\n",
    "    \"division\": \"\",\n",
    "    \"submitter\": \"dividiti\",\n",
    "    \"status\": \"available\",\n",
    "    \"system_name\": \"Firefly-RK3399\",\n",
    "\n",
    "    \"number_of_nodes\": \"1\",\n",
    "    \"host_processor_model_name\": \"Arm Corthttp://en.t-firefly.com/product/rk3399/ex-A72 MP2 (big); Arm Cortex-A53 MP4 (LITTLE)\",\n",
    "    \"host_processors_per_node\": \"1\",\n",
    "    \"host_processor_core_count\": \"2 (big); 4 (LITTLE)\",\n",
    "    \"host_processor_frequency\": \"1800 MHz (big), 1400 MHz (LITTLE)\",\n",
    "    \"host_processor_caches\": \"48 kB L1 instruction cache, 32 kB L1 data cache, 1 MB L2 unified cache (big); 32 kB L1 instruction cache, 32 kB L1 data cache, 512 kB L2 unified cache (LITTLE)\",    \n",
    "    \"host_memory_configuration\": \"-\",\n",
    "    \"host_memory_capacity\": \"4 GB\",\n",
    "    \"host_storage_capacity\": \"128 GB\",\n",
    "    \"host_storage_type\": \"SanDisk Extreme microSD\",\n",
    "    \"host_processor_interconnect\": \"-\",\n",
    "    \"host_networking\": \"-\",\n",
    "    \"host_networking_topology\": \"-\",\n",
    "\n",
    "    \"accelerators_per_node\": \"1\",\n",
    "    \"accelerator_model_name\": \"Arm Mali-T860 MP4\",\n",
    "    \"accelerator_frequency\": \"800 MHz\",\n",
    "    \"accelerator_host_interconnect\": \"-\",\n",
    "    \"accelerator_interconnect\": \"-\",\n",
    "    \"accelerator_interconnect_topology\": \"-\",\n",
    "    \"accelerator_memory_capacity\": \"4 GB (shared with host)\",\n",
    "    \"accelerator_memory_configuration\": \"-\",\n",
    "    \"accelerator_on-chip_memories\": \"-\",\n",
    "    \"cooling\": \"on-board fan\",\n",
    "    \"hw_notes\": \"http://en.t-firefly.com/product/rk3399/; http://opensource.rock-chips.com/wiki_RK3399\",\n",
    "\n",
    "    \"framework\": \"\",\n",
    "    \"operating_system\": \"Ubuntu 16.04.6 LTS\",\n",
    "    \"other_software_stack\": \"GCC 7.4.0; Python 3.5.2\",\n",
    "    \"sw_notes\": \"Powered by Collective Knowledge v1.11.1\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_firefly_tflite = deepcopy(firefly)\n",
    "open_firefly_tflite.update({\n",
    "    \"division\" : \"open\",\n",
    "    \"framework\" : \"TFLite-v1.15-rc2\"\n",
    "})\n",
    "open_firefly_tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closed_firefly_tflite = deepcopy(firefly)\n",
    "closed_firefly_tflite.update({\n",
    "    \"division\" : \"closed\",\n",
    "    \"framework\" : \"TFLite-v1.15-rc2\"\n",
    "})\n",
    "closed_firefly_tflite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "division_systems = {\n",
    "    'open-firefly-tflite-v1.15' : open_firefly_tflite,\n",
    "    'closed-firefly-tflite-v1.15' : closed_firefly_tflite\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate implementation_benchmarks dictionary.\n",
    "implementation_benchmarks = {}\n",
    "implementation = 'image-classification-tflite'\n",
    "\n",
    "implementation_mobilenet = implementation+'-'+'mobilenet'\n",
    "implementation_benchmarks[implementation_mobilenet] = {\n",
    "    \"input_data_types\": \"fp32\",\n",
    "    \"weight_data_types\": \"fp32\",\n",
    "    \"retraining\": \"no\",\n",
    "    \"starting_weights_filename\": \"https://zenodo.org/record/2269307/files/mobilenet_v1_1.0_224.tgz\",\n",
    "    \"weight_transformations\": \"TFLite\"\n",
    "}\n",
    "\n",
    "implementation_resnet = implementation+'-'+'resnet'\n",
    "implementation_benchmarks[implementation_resnet] = {\n",
    "    \"input_data_types\": \"fp32\",\n",
    "    \"weight_data_types\": \"fp32\",\n",
    "    \"retraining\": \"no\",\n",
    "    \"starting_weights_filename\": \"https://zenodo.org/record/2535873/files/resnet50_v1.pb\",\n",
    "    \"weight_transformations\": \"TF -> TFLite\"\n",
    "}\n",
    "\n",
    "# Add any MobileNets-v1,v2 model.\n",
    "def add_implementation_mobilenet(implementation_benchmarks, version, multiplier, resolution):\n",
    "    base_url = 'https://zenodo.org/record/2269307/files' if version == 1 else 'https://zenodo.org/record/2266646/files'\n",
    "    url = '{}/mobilenet_v{}_{}_{}.tgz'.format(base_url, version, multiplier, resolution)\n",
    "    benchmark = 'mobilenet-v{}-{}-{}'.format(version, multiplier, resolution)\n",
    "    if implementation == 'image-classification-tflite':\n",
    "        weights_transformations = 'TFLite'\n",
    "    elif implementation == 'image-classification-armnn-tflite':\n",
    "        weights_transformations = 'TFLite -> ArmNN'\n",
    "    else:\n",
    "        raise \"Unknown implementation '%s'!\" % implementation\n",
    "    implementation_benchmark = implementation+'-'+benchmark\n",
    "    implementation_benchmarks[implementation_benchmark] = {\n",
    "        \"input_data_types\": \"fp32\",\n",
    "        \"weight_data_types\": \"fp32\",\n",
    "        \"retraining\": \"no\",\n",
    "        \"starting_weights_filename\": url,\n",
    "        \"weight_transformations\": weights_transformations\n",
    "    }\n",
    "    return\n",
    "\n",
    "# MobileNet-v1.\n",
    "version = 1\n",
    "for multiplier in [ 1.0, 0.75, 0.5, 0.25 ]:\n",
    "    for resolution in [ 224, 192, 160, 128 ]:\n",
    "        add_implementation_mobilenet(implementation_benchmarks, version, multiplier, resolution)\n",
    "# MobileNet-v2.\n",
    "version = 2\n",
    "for multiplier in [ 1.0, 0.75, 0.5, 0.35 ]:\n",
    "    for resolution in [ 224, 192, 160, 128, 96 ]:\n",
    "        add_implementation_mobilenet(implementation_benchmarks, version, multiplier, resolution)\n",
    "add_implementation_mobilenet(implementation_benchmarks, version=2, multiplier=1.3, resolution=224)\n",
    "add_implementation_mobilenet(implementation_benchmarks, version=2, multiplier=1.4, resolution=224)\n",
    "\n",
    "# from pprint import pprint\n",
    "# pprint(implementation_benchmarks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defaults (to catch uninitialized descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system_desc_id.json\n",
    "default_system_json = {\n",
    "    \"division\": \"reqired\",\n",
    "    \"submitter\": \"required\",\n",
    "    \"status\": \"required\",\n",
    "    \"system_name\": \"required\",\n",
    "\n",
    "    \"number_of_nodes\": \"required\",\n",
    "    \"host_processor_model_name\": \"required\",\n",
    "    \"host_processors_per_node\": \"required\",\n",
    "    \"host_processor_core_count\": \"required\",\n",
    "    \"host_processor_frequency\": \"\",\n",
    "    \"host_processor_caches\": \"\",\n",
    "    \"host_memory_configuration\": \"\",\n",
    "    \"host_memory_capacity\": \"required\",\n",
    "    \"host_storage_capacity\": \"required\",\n",
    "    \"host_storage_type\": \"required\",\n",
    "    \"host_processor_interconnect\": \"\",\n",
    "    \"host_networking\": \"\",\n",
    "    \"host_networking_topology\": \"\",\n",
    "\n",
    "    \"accelerators_per_node\": \"required\",\n",
    "    \"accelerator_model_name\": \"required\",\n",
    "    \"accelerator_frequency\": \"\",\n",
    "    \"accelerator_host_interconnect\": \"\",\n",
    "    \"accelerator_interconnect\": \"\",\n",
    "    \"accelerator_interconnect_topology\": \"\",\n",
    "    \"accelerator_memory_capacity\": \"required\",\n",
    "    \"accelerator_memory_configuration\": \"\",\n",
    "    \"accelerator_on-chip_memories\": \"\",\n",
    "    \"cooling\": \"\",\n",
    "    \"hw_notes\": \"\",\n",
    "\n",
    "    \"framework\": \"required\",\n",
    "    \"operating_system\": \"required\",\n",
    "    \"other_software_stack\": \"required\",\n",
    "    \"sw_notes\": \"\"\n",
    "}\n",
    "\n",
    "# system_desc_id_imp.json\n",
    "default_implementation_benchmark_json = {\n",
    "    \"input_data_types\": \"required\",\n",
    "    \"retraining\": \"required\",\n",
    "    \"starting_weights_filename\": \"required\",\n",
    "    \"weight_data_types\": \"required\",\n",
    "    \"weight_transformations\": \"required\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"get\"></a>\n",
    "## Get the experimental data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download experimental data and add CK repositories as follows:\n",
    "```\n",
    "wget https://www.dropbox.com/s/jbpdh6c5d8fgwpl/mlperf.open.image-classification.firefly.zip\n",
    "$ ck add repo --zip=mlperf.open.image-classification.firefly.zip\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repos = [\n",
    "#    'mlperf.open.image-classification.firefly'\n",
    "    'mlperf.closed.image-classification.firefly'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for repo_uoa in repos:\n",
    "    !ck list $repo_uoa:experiment:* | sort\n",
    "    print (\"*\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"check\"></a>\n",
    "## Check the experimental data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_experimental_results(repo_uoa, module_uoa='experiment', tags='mlperf', submitter='dividiti', path=None):\n",
    "    if not path:\n",
    "        path_list = !ck find repo:$repo_uoa\n",
    "        path = path_list[0]\n",
    "    root_dir = os.path.join(path, 'submissions_inference_0_5')\n",
    "    if not os.path.exists(root_dir): os.mkdir(root_dir)\n",
    "    print(\"Storing results under '%s'\" % root_dir)\n",
    "    \n",
    "    r = ck.access({'action':'search', 'repo_uoa':repo_uoa, 'module_uoa':module_uoa, 'tags':tags})\n",
    "    if r['return']>0:\n",
    "        print('Error: %s' % r['error'])\n",
    "        exit(1)\n",
    "    experiments = r['lst']\n",
    "\n",
    "    dfs = []\n",
    "    for experiment in experiments:\n",
    "        data_uoa = experiment['data_uoa']\n",
    "        r = ck.access({'action':'list_points', 'repo_uoa':repo_uoa, 'module_uoa':module_uoa, 'data_uoa':data_uoa})\n",
    "        if r['return']>0:\n",
    "            print('Error: %s' % r['error'])\n",
    "            exit(1)\n",
    "        print (\"*\" * 80)\n",
    "        \n",
    "        tags = r['dict']['tags']\n",
    "        if 'accuracy' in tags:\n",
    "            if 'neon' in tags or 'opencl' in tags:\n",
    "                # Expected format: [ \"mlperf\", \"open\", \"image-classification\", \"firefly\", \"armnn-v19.08\", \"neon\", \"mobilenet-v1-0.5-128\", \"singlestream\", \"accuracy\", \"using-opencv\" ]\n",
    "                (_, division, task, platform, library, backend, benchmark, scenario, mode, preprocessing) = tags\n",
    "            else:\n",
    "                # Expected format: [ \"mlperf\", \"open\", \"image-classification\", \"firefly\", \"tflite-v1.15\", \"mobilenet-v1-0.5-128\", \"singlestream\", \"accuracy\", \"using-opencv\" ]\n",
    "                (_, division, task, platform, library, benchmark, scenario, mode, preprocessing) = tags\n",
    "        elif 'performance' in tags:            \n",
    "            if 'neon' in tags or 'opencl' in tags:\n",
    "                # Expected format: [ \"mlperf\", \"open\", \"image-classification\", \"firefly\", \"armnn-v19.08\", \"neon\", \"mobilenet-v1-0.5-128\", \"singlestream\", \"performance\" ]\n",
    "                (_, division, task, platform, library, backend, benchmark, scenario, mode) = tags\n",
    "            else:\n",
    "                # Expected format: [ \"mlperf\", \"open\", \"image-classification\", \"firefly\", \"tflite-v1.15\", \"mobilenet-v1-0.5-128\", \"singlestream\", \"performance\" ]\n",
    "                (_, division, task, platform, library, benchmark, scenario, mode) = tags\n",
    "        else:\n",
    "            raise \"Expected 'accuracy' or 'performance' in tags!\"\n",
    "            \n",
    "        organization = submitter\n",
    "        system = platform+'-'+library\n",
    "        division_system = division+'-'+system\n",
    "        if library.startswith('tflite'):\n",
    "            implementation = task+'-tflite'\n",
    "        elif library.startswith('armnn-tflite'):\n",
    "            implementation = task+'-armnn-tflite'\n",
    "        else: # Official app with CK adaptations.\n",
    "            implementation = 'mlperf-inference-vision'\n",
    "        implementation_benchmark = implementation+'-'+benchmark\n",
    "        \n",
    "        #\n",
    "        # Directory structure according to the Inference section of the General MLPerf Submission Rules:\n",
    "        # https://github.com/mlperf/policies/blob/master/submission_rules.adoc#552-inference\n",
    "        #\n",
    "        # <division>/\n",
    "        #   <organization>/\n",
    "        #\n",
    "        division_dir = os.path.join(root_dir, division)\n",
    "        if not os.path.exists(division_dir): os.mkdir(division_dir)\n",
    "        organization_dir = os.path.join(division_dir, organization)\n",
    "        if not os.path.exists(organization_dir): os.mkdir(organization_dir)\n",
    "        \n",
    "        #\n",
    "        #     \"systems\"/\n",
    "        #       <system_desc_id>.json\n",
    "        #\n",
    "        systems_dir = os.path.join(organization_dir, 'systems')\n",
    "        if not os.path.exists(systems_dir): os.mkdir(systems_dir)\n",
    "        system_json_name = '%s.json' % system\n",
    "        system_json_path = os.path.join(systems_dir, system_json_name)\n",
    "        with open(system_json_path, 'w') as system_json_file:\n",
    "            system_json = division_systems.get(division_system, default_system_json)\n",
    "            json.dump(system_json, system_json_file, indent=2)\n",
    "            print('%s' % systems_dir)\n",
    "            if system_json == default_system_json:\n",
    "                print('  |_ %s [DEFAULT]' % system_json_name)\n",
    "                raise\n",
    "            else:\n",
    "                print('  |_ %s [%s]' % (system_json_name, division_system))\n",
    "        \n",
    "        #\n",
    "        #     \"code\"/\n",
    "        #       <benchmark_name_per_reference>/\n",
    "        #         <implementation_id>/\n",
    "        #           <Code interface with loadgen and other arbitrary stuff>\n",
    "        #\n",
    "        code_dir = os.path.join(organization_dir, 'code')\n",
    "        if not os.path.exists(code_dir): os.mkdir(code_dir)\n",
    "        # FIXME: For now, not always \"per reference\".\n",
    "        benchmark_dir = os.path.join(code_dir, benchmark)\n",
    "        if not os.path.exists(benchmark_dir): os.mkdir(benchmark_dir)\n",
    "        implementation_dir = os.path.join(benchmark_dir, implementation)\n",
    "        if not os.path.exists(implementation_dir): os.mkdir(implementation_dir)\n",
    "        print('%s' % code_dir)\n",
    "        print('  |_ %s [DEFAULT]' % implementation)\n",
    "        # TODO: Add basic description of image-classification-{tflite,armnn-tflite}.\n",
    "        \n",
    "        #\n",
    "        #     \"measurements\"/\n",
    "        #       <system_desc_id>/\n",
    "        #         <benchmark>/\n",
    "        #           <scenario>/\n",
    "        #             <system_desc_id>_<implementation_id>.json\n",
    "        #             README.md\n",
    "        #             user.conf\n",
    "        #             mlperf.conf\n",
    "        #             calibration_process.adoc (?)\n",
    "        #\n",
    "        measurements_dir = os.path.join(organization_dir, 'measurements')\n",
    "        if not os.path.exists(measurements_dir): os.mkdir(measurements_dir)\n",
    "        system_dir = os.path.join(measurements_dir, system)\n",
    "        if not os.path.exists(system_dir): os.mkdir(system_dir)\n",
    "        benchmark_dir = os.path.join(system_dir, benchmark)\n",
    "        if not os.path.exists(benchmark_dir): os.mkdir(benchmark_dir)\n",
    "        scenario_dir = os.path.join(benchmark_dir, scenario)\n",
    "        if not os.path.exists(scenario_dir): os.mkdir(scenario_dir)\n",
    "        print(scenario_dir)\n",
    "        # Touch empty files.\n",
    "        # <system_desc_id>_<implementation_id>.json\n",
    "        system_implementation_json_name = system+'_'+implementation+'.json'\n",
    "        system_implementation_json_path = os.path.join(scenario_dir, system_implementation_json_name)\n",
    "        with open(system_implementation_json_path, 'w') as system_implementation_json_file:\n",
    "            implementation_benchmark_json = implementation_benchmarks.get(implementation_benchmark, default_implementation_benchmark_json)\n",
    "            json.dump(implementation_benchmark_json, system_implementation_json_file, indent=2)\n",
    "            if implementation_benchmark_json == default_implementation_benchmark_json:\n",
    "                print('  |_ %s [DEFAULT]' % system_implementation_json_name)\n",
    "                raise\n",
    "            else:\n",
    "                print('  |_ %s [%s]' % (system_implementation_json_name, implementation_benchmark))\n",
    "        # README.md\n",
    "        readme_name = 'README.md'\n",
    "        readme_path = os.path.join(scenario_dir, readme_name)\n",
    "        with open(readme_path, 'a'):\n",
    "            os.utime(readme_path, None)\n",
    "            print('  |_ %s [EMPTY]' % readme_name)\n",
    "        # user.conf\n",
    "        user_conf_name = 'user.conf'\n",
    "        user_conf_path = os.path.join(scenario_dir, user_conf_name)\n",
    "        with open(user_conf_path, 'a'):\n",
    "            os.utime(user_conf_path, None)\n",
    "            print('  |_ %s [EMPTY]' % user_conf_name)\n",
    "        # mlperf.conf\n",
    "        mlperf_conf_name = 'mlperf.conf'\n",
    "        mlperf_conf_path = os.path.join(scenario_dir, mlperf_conf_name)\n",
    "        with open(mlperf_conf_path, 'a'):\n",
    "            os.utime(mlperf_conf_path, None)\n",
    "            print('  |_ %s [EMPTY]' % mlperf_conf_name)\n",
    "        \n",
    "        #\n",
    "        #     \"results\"/\n",
    "        #       <system_desc_id>/\n",
    "        #         <benchmark>/\n",
    "        #           <scenario>/\n",
    "        #             performance/\n",
    "        #               run_x/ # 1 run for single stream and offline, 5 otherwise\n",
    "        #                 mlperf_log_summary.txt\n",
    "        #                 mlperf_log_detail.txt\n",
    "        #                 mlperf_log_trace.json\n",
    "        #             accuracy/\n",
    "        #               mlperf_log_accuracy.json\n",
    "        #       compliance_checker_log.txt (?)\n",
    "        #\n",
    "        results_dir = os.path.join(organization_dir, 'results')\n",
    "        if not os.path.exists(results_dir): os.mkdir(results_dir)\n",
    "        system_dir = os.path.join(results_dir, system)\n",
    "        if not os.path.exists(system_dir): os.mkdir(system_dir)\n",
    "        benchmark_dir = os.path.join(system_dir, benchmark)\n",
    "        if not os.path.exists(benchmark_dir): os.mkdir(benchmark_dir)\n",
    "        scenario_dir = os.path.join(benchmark_dir, scenario)\n",
    "        if not os.path.exists(scenario_dir): os.mkdir(scenario_dir)\n",
    "        mode_dir = os.path.join(scenario_dir, mode)\n",
    "        if not os.path.exists(mode_dir): os.mkdir(mode_dir)\n",
    "        # For each point (should be one point for each performance run).\n",
    "        points = r['points']\n",
    "        for (point, point_idx) in zip(points, range(1,len(points)+1)):\n",
    "            point_file_path = os.path.join(r['path'], 'ckp-%s.0001.json' % point)\n",
    "            with open(point_file_path) as point_file:\n",
    "                point_data_raw = json.load(point_file)\n",
    "            characteristics_list = point_data_raw['characteristics_list']\n",
    "            characteristics = characteristics_list[0]\n",
    "            # Set the leaf directory.\n",
    "            if mode == 'performance':\n",
    "                run_dir = os.path.join(mode_dir, 'run_%d' % point_idx)\n",
    "                if not os.path.exists(run_dir): os.mkdir(run_dir)\n",
    "                last_dir = run_dir\n",
    "            else:\n",
    "                last_dir = mode_dir\n",
    "            print(last_dir)\n",
    "            # Dump files in the leaf directory.\n",
    "            mlperf_log = characteristics['run'].get('mlperf_log',{})\n",
    "            # Summary file (with errors and warnings in accuracy mode, with statistics in performance mode).\n",
    "            summary_txt_name = 'mlperf_log_summary.txt'\n",
    "            summary_txt_path = os.path.join(last_dir, summary_txt_name)\n",
    "            with open(summary_txt_path, 'w') as summary_txt_file:\n",
    "                summary_txt_file.writelines(mlperf_log.get('summary',''))\n",
    "                print('  |_ %s' % summary_txt_name)\n",
    "            # Detail file (with settings).\n",
    "            detail_txt_name = 'mlperf_log_detail.txt'\n",
    "            detail_txt_path = os.path.join(last_dir, detail_txt_name)\n",
    "            with open(detail_txt_path, 'w') as detail_txt_file:\n",
    "                detail_txt_file.writelines(mlperf_log.get('detail',''))\n",
    "                print('  |_ %s' % detail_txt_name)\n",
    "            # Accuracy file (with accuracy dictionary).\n",
    "            # FIXME: Move the next 5 lines into the (if mode == 'accuracy') block,\n",
    "            # once the submission checker no longer complains as follows:\n",
    "            # \"performance/run_1 has file list mismatch (['mlperf_log_accuracy.json'])\"\n",
    "            accuracy_json_name = 'mlperf_log_accuracy.json'\n",
    "            accuracy_json_path = os.path.join(last_dir, accuracy_json_name)\n",
    "            with open(accuracy_json_path, 'w') as accuracy_json_file:\n",
    "                json.dump(mlperf_log.get('accuracy',{}), accuracy_json_file, indent=2)\n",
    "                print('  |_ %s' % accuracy_json_name)\n",
    "            if mode == 'accuracy':\n",
    "                # FIXME: Do not hardcode - locate via CK.\n",
    "                accuracy_imagenet_py = '$HOME/CK_TOOLS/mlperf-inference-upstream.master/inference/v0.5/classification_and_detection/tools/accuracy-imagenet.py'\n",
    "                imagenet_val_file = '$HOME/CK_TOOLS/dataset-imagenet-ilsvrc2012-aux/val.txt'\n",
    "                accuracy_txt_name = 'accuracy.txt'\n",
    "                accuracy_txt_path = os.path.join(last_dir, accuracy_txt_name)\n",
    "                accuracy_txt = !python3 $accuracy_imagenet_py --imagenet-val-file $imagenet_val_file --mlperf-accuracy-file $accuracy_json_path\n",
    "                with open(accuracy_txt_path, 'w') as accuracy_txt_file:\n",
    "                    accuracy_txt_file.writelines(accuracy_txt)\n",
    "                    # Print the first line containing accuracy info.\n",
    "                    print('  |_ %s (\"%s\")' % (accuracy_txt_name, accuracy_txt[0]))\n",
    "#             # Trace file (should omit trace from v0.5).\n",
    "#             trace_json_name = 'mlperf_log_trace.json'\n",
    "#             trace_json_path = os.path.join(last_dir, trace_json_name)\n",
    "#             with open(trace_json_path, 'w') as trace_json_file:\n",
    "#                 json.dump(mlperf_log.get('trace',{}), trace_json_file, indent=2)\n",
    "\n",
    "    print (\"*\" * 80)\n",
    "    # FIXME: Do not hardcode - locate via CK.\n",
    "    submission_checker_py = '$HOME/CK_TOOLS/mlperf-inference-upstream.master/inference/v0.5/tools/submission/submission-checker.py'\n",
    "    !python3 $submission_checker_py --input $root_dir --submitter $submitter\n",
    "    \n",
    "    return dfs\n",
    "\n",
    "dfs = get_experimental_results(repo_uoa)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
