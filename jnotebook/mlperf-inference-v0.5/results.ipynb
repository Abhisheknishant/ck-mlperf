{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [MLPerf Inference Results v0.5](https://github.com/mlperf/inference/tree/master/v0.5)\n",
    "## Automatic results table generation (c) [dividiti](http://dividiti.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Includes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython as ip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mp\n",
    "# import seaborn as sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('IPython version: %s' % ip.__version__)\n",
    "print ('Pandas version: %s' % pd.__version__)\n",
    "print ('NumPy version: %s' % np.__version__)\n",
    "print ('Matplotlib version: %s' % mp.__version__)\n",
    "# print ('Seaborn version: %s' % sb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "def display_in_full(df):\n",
    "    pd.options.display.max_columns = len(df.columns)\n",
    "    pd.options.display.max_rows = len(df.index)\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divisions = [ 'closed', 'open' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maps for DataFrame construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase or camelcase or camelcase with space to camelcase.\n",
    "scenario_to_str = {\n",
    "    # SingleStream.\n",
    "    'singlestream'  : 'SingleStream',\n",
    "    'SingleStream'  : 'SingleStream',\n",
    "    'Single Stream' : 'SingleStream',\n",
    "    # MultiStream.\n",
    "    'multistream'   : 'MultiStream',\n",
    "    'MultiStream'   : 'MultiStream',\n",
    "    'Multi Stream'  : 'MultiStream',\n",
    "    # Server.\n",
    "    'server'        : 'Server',\n",
    "    'Server'        : 'Server',\n",
    "    # Offline.\n",
    "    'offline'       : 'Offline',\n",
    "    'Offline'       : 'Offline',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "division_to_str = {\n",
    "    # Open.\n",
    "    'open'   : 'Open',\n",
    "    'Open'   : 'Open',\n",
    "    # Closed.\n",
    "    'closed' : 'Closed',\n",
    "    'Closed' : 'Closed'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividiti-specific.\n",
    "system_id_to_processor = {\n",
    "    'firefly'   : 'Rockchip RK3399',\n",
    "    'hikey960'  : 'HiSilicon Kirin960',\n",
    "    'mate10pro' : 'HiSilicon Kirin970',\n",
    "    'rpi4'      : 'Broadcom BCM2711B0',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics for DataFrame construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance metrics: Stream in ms; MultiStream in #streams; Server in QPS; Offline in inputs/s).\n",
    "performance_columns = [\n",
    "    'P_{}_{}'.format(task, scenario)\n",
    "    for task in ['IC1','IC2','OD1','OD2','NMT'] \n",
    "    for scenario in ['SS','MS','S','O']\n",
    "]\n",
    "# Accuracy metrics: Image Classification in Top1, %; Object Detection in mAP, %; Machine Translation in BLUE.\n",
    "accuracy_columns = [\n",
    "    'A_{}_{}'.format(task, scenario)\n",
    "    for task in ['IC1','IC2','OD1','OD2','NMT']\n",
    "    for scenario in ['SS','MS','S','O']\n",
    "]\n",
    "# Score columns.\n",
    "score_columns = performance_columns + accuracy_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-imagenet benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_imagenet_benchmarks = {\n",
    "    # Non-ImageNet benchmarks from the closed division.\n",
    "    'ssd-small': {\n",
    "        \"name\"  : \"SSD-MobileNet-v1\",\n",
    "        \"width\" : 300,\n",
    "        \"height\": 300,\n",
    "    },\n",
    "    'ssd-large': {\n",
    "        \"name\"  : \"SSD-ResNet34\",\n",
    "        \"width\" : 1200,\n",
    "        \"height\": 1200,\n",
    "    },\n",
    "    'gnmt' : {\n",
    "        \"name\"  : \"GNMT\",\n",
    "        \"width\" : -1,\n",
    "        \"height\": -1,\n",
    "    },\n",
    "    # Non-ImageNet benchmarks from the open division.\n",
    "    'rcnn-nas-lowproposals' : {\n",
    "        \"name\" : \"Faster-RCNN-NAS lowproposals\",\n",
    "        \"url\" : \"http://download.tensorflow.org/models/object_detection/faster_rcnn_nas_lowproposals_coco_2018_01_28.tar.gz\",\n",
    "        \"width\" : 1200,\n",
    "        \"height\" : 1200,\n",
    "    },\n",
    "    'rcnn-resnet50-lowproposals' : {\n",
    "        \"name\" : \"Faster-RCNN-ResNet50 lowproposals\",\n",
    "        \"url\" : \"http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet50_lowproposals_coco_2018_01_28.tar.gz\",\n",
    "        \"width\" : 1024,\n",
    "        \"height\" : 600,\n",
    "    },\n",
    "    'rcnn-resnet101-lowproposals' : {\n",
    "        \"name\" : \"Faster-RCNN-ResNet101 lowproposals\",\n",
    "        \"url\" : \"http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet101_lowproposals_coco_2018_01_28.tar.gz\",\n",
    "        \"width\" : 1024,\n",
    "        \"height\" : 600,\n",
    "    },\n",
    "    'rcnn-inception-resnet-v2-lowproposals' : {\n",
    "        \"name\" : \"Faster-RCNN-Inception-ResNet-v2 lowproposals\",\n",
    "        \"url\" : \"http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_resnet_v2_atrous_lowproposals_coco_2018_01_28.tar.gz\",\n",
    "        \"width\" : 1024,\n",
    "        \"height\" : 600,\n",
    "    },\n",
    "    'rcnn-inception-v2' : {\n",
    "        \"name\" : \"Faster-RCNN Inception-v2\",\n",
    "        \"url\" : \"http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_v2_coco_2018_01_28.tar.gz\",\n",
    "        \"width\" : 1024,\n",
    "        \"height\" : 600,\n",
    "    },\n",
    "    'ssd-inception-v2' : {\n",
    "        \"name\" : \"SSD-Inception-v2\",\n",
    "        \"url\" : \"http://download.tensorflow.org/models/object_detection/ssd_inception_v2_coco_2018_01_28.tar.gz\",\n",
    "        \"width\" : 300,\n",
    "        \"height\" : 300,\n",
    "    },\n",
    "    'ssd-mobilenet-v1-quantized-mlperf' : {\n",
    "        \"name\" : \"SSD-MobileNet-v1\",\n",
    "        \"url\" : \"https://zenodo.org/record/3361502/files/ssd_mobilenet_v1_coco_2018_01_28.tar.gz\",\n",
    "        \"width\" : 300,\n",
    "        \"height\" : 300,\n",
    "        \"provenance\" : \"Google\",\n",
    "    },\n",
    "    'ssd-mobilenet-v1-non-quantized-mlperf' : {\n",
    "        \"name\" : \"SSD-MobileNet-v1 quantized\",\n",
    "        \"url\" : \"https://zenodo.org/record/3252084/files/mobilenet_v1_ssd_8bit_finetuned.tar.gz\",\n",
    "        \"width\" : 300,\n",
    "        \"height\" : 300,\n",
    "        \"provenance\" : \"Habana\"\n",
    "    },\n",
    "    'ssd-mobilenet-v1-fpn' : {\n",
    "        \"name\" : \"SSD-MobileNet-v1 FPN SBP\",\n",
    "        \"url\" : \"http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03.tar.gz\",\n",
    "        \"width\" : 640,\n",
    "        \"height\" : 640,\n",
    "    },\n",
    "    'ssd-resnet50-fpn' : {\n",
    "        \"name\" : \"SSD-ResNet50-v1 FPN SBP\",\n",
    "        \"url\" : \"http://download.tensorflow.org/models/object_detection/ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03.tar.gz\",\n",
    "        \"width\" : 640,\n",
    "        \"height\" : 640,\n",
    "    },\n",
    "    'ssdlite-mobilenet-v2' : {\n",
    "        \"name\" : \"SSDLite-MobileNet-v2\",\n",
    "        \"url\" : \"http://download.tensorflow.org/models/object_detection/ssdlite_mobilenet_v2_coco_2018_05_09.tar.gz\",\n",
    "        \"width\" : 300,\n",
    "        \"height\" : 300,\n",
    "    },\n",
    "    'yolo-v3' : {\n",
    "        \"name\" : \"YOLO-v3\",\n",
    "        \"url\" : \"https://zenodo.org/record/3386327/files/yolo_v3_coco.tar.gz\",\n",
    "        \"width\" : 416,\n",
    "        \"height\" : 416,\n",
    "        \"provenance\" : \"https://github.com/YunYang1994/tensorflow-yolov3/\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = '/home/anton/projects/mlperf/submissions_inference_0_5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dfs = []\n",
    "# FOR EACH division.\n",
    "for division in divisions:\n",
    "    #if division != 'open': continue # skip for now\n",
    "    # FOR EACH submitter.\n",
    "    submitters_dir = os.path.join(results_path, division)\n",
    "    submitters = [ fn for fn in os.listdir(submitters_dir) if os.path.isdir(os.path.join(submitters_dir, fn)) ]\n",
    "    for submitter in submitters:\n",
    "        # Selectively filter out submitters.\n",
    "        #all_submitters_closed = [ 'Alibaba', 'CentaurTechnology', 'DellEMC', 'dividiti', 'FuriosaAI', 'Google', 'Habana', 'Hailo', 'Intel', 'NVIDIA', 'Qualcomm', 'Tencent' ]\n",
    "        #if division == 'closed' and submitter not in all_submitters_closed: continue\n",
    "        #all_submitters_open = [ 'dividiti', 'Habana', 'Inspur', 'NVIDIA', 'Qualcomm' ]\n",
    "        #if division == 'open' and submitter not in all_submitters_open: continue\n",
    "        # FOR EACH system.\n",
    "        results_dir = os.path.join(submitters_dir, submitter, 'results')\n",
    "        systems = [ fn for fn in os.listdir(results_dir) if os.path.isdir(os.path.join(results_dir, fn)) ]\n",
    "        for system in systems:\n",
    "            system_dir = os.path.join(results_dir, system)\n",
    "            system_json_name = system + '.json'\n",
    "            system_json_path = os.path.join(submitters_dir, submitter, 'systems', system_json_name)\n",
    "            with open(system_json_path) as system_json_file:\n",
    "                system_json = json.load(system_json_file)\n",
    "\n",
    "            # Category.\n",
    "            if system_json['status'] in [ 'available', 'Available' ]:\n",
    "                category = 'Available'\n",
    "            elif system_json['status'] in [ 'preview', 'Preview' ]:\n",
    "                category = 'Preview'\n",
    "            elif system_json['status'] in [ 'rdi', 'RDI' ]:\n",
    "                category = 'Research, Development, Other'\n",
    "            else:\n",
    "                raise Exception(\"Unsupported category '%s'!\" % (system_json['status']))\n",
    "\n",
    "            # System details.\n",
    "            system_name = system_json['system_name']\n",
    "            system_list = system.split('-')\n",
    "            system_id = system_list[0]                \n",
    "                \n",
    "            # Processor (CPU).\n",
    "            processor = system_id_to_processor.get(system_id, system_json.get('host_processor_model_name', 'N/A'))\n",
    "            processor_num = int(system_json.get('host_processors_per_node', -1))\n",
    "\n",
    "            # Accelerator.\n",
    "            # Tencent: https://github.com/mlperf/submissions_inference_0_5/issues/285\n",
    "            accelerator = system_json.get('accelerator_model_name', 'N/A')\n",
    "            accelerator_num = int(system_json.get('accelerators_per_node', -1))\n",
    "\n",
    "            # Software (framework).\n",
    "            software = system_json['framework']\n",
    "\n",
    "            # Default form factors and notes.\n",
    "            ff_m = ff_d = ff_s = ff_e = ''\n",
    "            notes = ''                \n",
    "                \n",
    "            # Submitter-specific form factors and notes.\n",
    "            submitter_str = submitter\n",
    "            if submitter == 'dividiti':\n",
    "                # Form factors.\n",
    "                if system_id in [ 'hikey960', 'firefly', 'rpi4' ]: ff_e = 'x'\n",
    "                if system_id in [ 'mate10pro', 'hikey960' ]: ff_m = 'x'\n",
    "                if system_id in [ 'velociti' ]: ff_d = 'x'\n",
    "                # Notes.\n",
    "                if system_id == 'hikey960':\n",
    "                    notes = 'Mobile chip in embedded form factor (development board).'\n",
    "                if division == 'open':\n",
    "                    # Object Detection is collaboration between dividiti and Politecnico di Milano.\n",
    "                    if system_id == 'velociti': submitter_str = 'dividiti + PoliMi'\n",
    "                    if system == 'velociti-tensorflow-v1.14-cpu':\n",
    "                        notes = 'In the Other category, since this Intel CPU is no longer available (end-of-life).'\n",
    "            elif submitter == 'Alibaba':\n",
    "                ff_s = 'x'\n",
    "                if system_id == 'alibaba_cloud_t4':\n",
    "                    notes = 'ECC off'\n",
    "            elif submitter == 'DellEMC':\n",
    "                ff_s = 'x'\n",
    "                if system_id == 'R740_T4x4_tensorrt':\n",
    "                    notes = 'ECC off'\n",
    "            elif submitter == 'Google':\n",
    "                ff_s = 'x'\n",
    "                # FIXME: What's 8?\n",
    "                accelerator_name = 'TPU v3-8'\n",
    "                system_name = '{:d}x Cloud {:s}'.format(int(accelerator_num/8), accelerator_name)\n",
    "            elif submitter == 'Habana':\n",
    "                ff_d = ff_s = ff_e = 'x'\n",
    "                if division == 'open':\n",
    "                    if system_id == 'Goya_fast_latency':\n",
    "                        notes = 'Low latency results ...'\n",
    "                    if system_id == 'Goya_med_latency':\n",
    "                        notes = 'Medium latency results ...'  \n",
    "            elif submitter == 'Intel':\n",
    "                if system_id == 'ICL':\n",
    "                    ff_m = 'x'\n",
    "                else:\n",
    "                    ff_s = 'x'\n",
    "            elif submitter == 'NVIDIA':\n",
    "                if system_id == 'Xavier':\n",
    "                    ff_e = 'x'\n",
    "                    if division == 'closed':\n",
    "                        notes = 'GPU and both DLAs are used in Offline and MultiStream'\n",
    "                elif system_id == 'TitanRTXx4':\n",
    "                    ff_e = ff_s = ff_d = 'x'\n",
    "                elif system_id == 'T4x8':\n",
    "                    ff_e = ff_s = 'x'\n",
    "                elif system_id == 'T4x20':\n",
    "                    ff_s = 'x'\n",
    "                else:\n",
    "                    raise Exception(\"Unsupported NVIDIA system '%s'!\" % system_id)                    \n",
    "            elif submitter == 'Qualcomm':\n",
    "                ff_m = 'x'\n",
    "                if division == 'open':\n",
    "                    notes = 'Median latency. MultiStream: Both Hexagon Vector Extensions (HVX) and Hexagon Tensor Accelerator (HTA).'\n",
    "                if division == 'closed':\n",
    "                    notes = 'Hexagon Vector Extensions being used.'\n",
    "            elif submitter == 'Tencent':\n",
    "                ff_s = 'x'\n",
    "            # Preview only.\n",
    "            elif submitter == 'CentaurTechnology':\n",
    "                ff_d = ff_s = ff_e = 'x'\n",
    "            elif submitter == 'Hailo':\n",
    "                ff_d = ff_e = 'x'\n",
    "            # RDO only.\n",
    "            elif submitter == 'FuriosaAI':\n",
    "                ff_d = ff_s = ff_e = 'x'\n",
    "            # Open only.\n",
    "            elif submitter == 'Inspur':\n",
    "                ff_s = 'x'\n",
    "            else:\n",
    "                raise Exception(\"Unsupported division/submitter combination '%s'/'%s'!\" % (division, submitter))\n",
    "\n",
    "            # Create DataFrame for each row of the final table based on the division, submitter and system.\n",
    "            data = [{\n",
    "                # \n",
    "                'ID'            : '-', # TODO: Fill in later.\n",
    "                'Submitter'     : submitter_str,\n",
    "                'System'        : system_name,\n",
    "                'Benchmark'     : '-', # TODO: Fill in later.\n",
    "                # Processor.\n",
    "                'Processor'     : processor,\n",
    "                'Processor #'   : processor_num,\n",
    "                # Accelerator.\n",
    "                'Accelerator'   : accelerator,\n",
    "                'Accelerator #' : accelerator_num if accelerator_num != '0' else '',\n",
    "                # Software.\n",
    "                'Software' : software,\n",
    "                # Form factor.\n",
    "                'FF_M'     : ff_m,\n",
    "                'FF_D'     : ff_d,\n",
    "                'FF_S'     : ff_s,\n",
    "                'FF_E'     : ff_e,\n",
    "                # Details. Code. Notes.\n",
    "                'Details'  : 'https://github.com/mlperf/inference_results_v0.5/blob/master/{}/{}/systems/{}'. \\\n",
    "                                    format(division, submitter, system_json_name),\n",
    "                'Code'     : 'https://github.com/mlperf/inference_results_v0.5/tree/master/{}/{}/code'. \\\n",
    "                                    format(division, submitter),\n",
    "                'Notes'    : notes,\n",
    "                # Misc.\n",
    "                'Division' : division_to_str.get(division, division),\n",
    "                'Category' : category,\n",
    "#                 'Task'     : task,\n",
    "#                 'Scenario' : scenario_to_str.get(scenario, scenario),\n",
    "            }]\n",
    "            # NB: 'Accelerator #' is important to sort Google's submissions correctly (not lexicographically).\n",
    "            index = [\n",
    "                'Division', 'Category', 'Submitter', 'Accelerator #', 'System', 'Software', 'Benchmark' #, 'Task', 'Scenario'\n",
    "            ]\n",
    "            # Reset all scores.\n",
    "            data[0].update({ score : '' for score in score_columns })\n",
    "\n",
    "            # FOR EACH benchmark.\n",
    "            benchmarks = [ fn for fn in os.listdir(system_dir) if os.path.isdir(os.path.join(system_dir, fn)) ]\n",
    "            for (benchmark, benchmark_idx) in zip(benchmarks, range(len(benchmarks))):\n",
    "                is_last_benchmark = (benchmark_idx == len(benchmarks) - 1)\n",
    "                # Benchmark (with notes).\n",
    "                benchmark_dict = non_imagenet_benchmarks.get(benchmark)\n",
    "                if benchmark_dict:\n",
    "                    width = benchmark_dict['width']\n",
    "                    height = benchmark_dict['height']\n",
    "                else:\n",
    "                    if benchmark.endswith('96'):\n",
    "                        side = 96\n",
    "                    elif benchmark.endswith('128'):\n",
    "                        side = 128\n",
    "                    elif benchmark.endswith('160'):\n",
    "                        side = 160\n",
    "                    elif benchmark.endswith('192'):\n",
    "                        side = 192\n",
    "                    else:\n",
    "                        side = 224\n",
    "                    width = side\n",
    "                    height = side\n",
    "                if width != -1 and height != -1:\n",
    "                    # Benchmark (width x height).\n",
    "                    benchmark_with_notes = '{} ({}x{})'.format(benchmark, width, height)\n",
    "                else:\n",
    "                    # GNMT.\n",
    "                    benchmark_with_notes = benchmark                \n",
    "                # TODO: Rename to 'Model used, if not Closed Division default' for Open. Drop for Closed.\n",
    "                if division == 'open':\n",
    "                    data[0]['Benchmark'] = benchmark_with_notes\n",
    "\n",
    "                # FOR EACH scenario.\n",
    "                benchmark_dir = os.path.join(system_dir, benchmark)\n",
    "                scenarios = [ fn for fn in os.listdir(benchmark_dir) if os.path.isdir(os.path.join(benchmark_dir, fn)) ]\n",
    "                for scenario in scenarios:\n",
    "                    scenario_str = scenario_to_str.get(scenario,'')\n",
    "                    if scenario_str not in [ 'SingleStream', 'MultiStream', 'Server', 'Offline' ]: continue\n",
    "                    experiment_dir = os.path.join(benchmark_dir, scenario)\n",
    "                    # Extract accuracy.\n",
    "                    if submitter == 'Hailo' and benchmark == 'ssd-small':\n",
    "                         # https://github.com/mlperf/submissions_inference_0_5/issues/287\n",
    "                        task = 'OD'\n",
    "                        accuracy = 21.920 # ssd-small/SingleStream/accuracy/results.json\n",
    "                    else:\n",
    "                        accuracy_dir = os.path.join(experiment_dir, 'accuracy')\n",
    "                        with open(os.path.join(accuracy_dir, 'accuracy.txt'), 'r') as accuracy_file:\n",
    "                            accuracy_txt = accuracy_file.readlines()\n",
    "                            accuracy_line = accuracy_txt[-1]\n",
    "                        if accuracy_line.startswith('mAP'):\n",
    "                            task = 'OD'\n",
    "                            match = re.match('mAP\\=([\\d\\.]+)\\%', accuracy_line)\n",
    "                            accuracy = float(match.group(1))\n",
    "                        elif accuracy_line.startswith('accuracy'):\n",
    "                            task = 'IC'\n",
    "                            match = re.match('accuracy=(.+)%, good=(\\d+), total=(\\d+)', accuracy_line)\n",
    "                            accuracy = float(match.group(1))\n",
    "                        elif accuracy_line.startswith('BLEU'):\n",
    "                            task = 'MT'\n",
    "                            match = re.match('BLEU:\\s*(.+)', accuracy_line)\n",
    "                            accuracy = float(match.group(1))\n",
    "                        else:\n",
    "                            pprint(accuracy_txt)\n",
    "                            raise Exception('Failed to extract accuracy information from \"%s\"' % accuracy_line)\n",
    "\n",
    "                    if scenario_str in [ 'SingleStream', 'MultiStream', 'Offline', 'Server' ]:\n",
    "                        if submitter == 'Tencent' and scenario_str in [ 'SingleStream', 'Offline' ]:\n",
    "                            # https://github.com/mlperf/submissions_inference_0_5/issues/286\n",
    "                            performance_dir = os.path.join(experiment_dir, 'performance')\n",
    "                        else:\n",
    "                            # TODO: Iterate over 5 runs for Server.\n",
    "                            performance_dir = os.path.join(experiment_dir, 'performance', 'run_1')                            \n",
    "                        with open(os.path.join(performance_dir, 'mlperf_log_summary.txt'), 'r') as summary_file:\n",
    "                            summary_txt = summary_file.readlines()\n",
    "                            for line in summary_txt:\n",
    "                                if re.match(\"Scenario\", line):\n",
    "                                    # NB: LoadGen scenario strings have spaces between 'Single'/'Multi' and 'Stream'.\n",
    "                                    loadgen_scenario = line.split(\": \",1)[1].strip()\n",
    "                                    loadgen_scenario_str = scenario_to_str[loadgen_scenario]\n",
    "                                    if loadgen_scenario_str != scenario_str:\n",
    "                                        raise Exception(\"Expected '%s', parsed '%s'!\" % (scenario_str, loadgen_scenario_str ))\n",
    "                                    continue\n",
    "                                if scenario_str == \"SingleStream\":\n",
    "                                    if re.match(\"90th percentile latency\", line):\n",
    "                                        score = line.split(\": \",1)[1].strip()\n",
    "                                        continue\n",
    "                                if scenario_str == \"MultiStream\":\n",
    "                                    if re.match(\"Samples per query\", line):\n",
    "                                        score = line.split(\": \",1)[1].strip()\n",
    "                                        continue\n",
    "                                if scenario_str == \"Server\":\n",
    "                                    if re.match(\"Scheduled samples per second\", line):\n",
    "                                        score = line.split(\": \",1)[1].strip()\n",
    "                                        continue\n",
    "                                if scenario_str == \"Offline\":\n",
    "                                    if re.match(\"Samples per second\", line):\n",
    "                                        score = line.split(\": \",1)[1].strip()\n",
    "                                        continue\n",
    "                        if scenario_str == 'SingleStream':\n",
    "                            time_ns = int(score)\n",
    "                            time_ms = time_ns * 1e-6\n",
    "                        elif scenario_str == 'MultiStream':\n",
    "                            num_streams = int(score)\n",
    "                        elif scenario_str == 'Server':\n",
    "                            queries_per_second = float(score)\n",
    "                        elif scenario_str == 'Offline':\n",
    "                            samples_per_second = float(score)\n",
    "                    else:\n",
    "                        raise Exception(\"Unsupported scenario '%s'!\" % scenario_str)\n",
    "                        \n",
    "                    # Tasks.\n",
    "                    ic1 = (task=='IC' and benchmark.startswith('mobilenet'))\n",
    "                    ic2 = (task=='IC' and benchmark.startswith('resnet'))\n",
    "                    od1 = (task=='OD' and benchmark=='ssd-small')\n",
    "                    od2 = (task=='OD' and (benchmark=='ssd-large' or system_id=='velociti'))\n",
    "                    nmt = (task=='MT')\n",
    "                    \n",
    "                    if scenario_str == 'SingleStream':\n",
    "                        performance_str = '{:.03f}'.format(time_ms)\n",
    "                        accuracy_str    = '{:.03f}'.format(accuracy)\n",
    "                        if ic1:\n",
    "                            data[0]['A_IC1_SS'] = accuracy_str\n",
    "                            data[0]['P_IC1_SS'] = performance_str\n",
    "                        elif ic2:\n",
    "                            data[0]['A_IC2_SS'] = accuracy_str\n",
    "                            data[0]['P_IC2_SS'] = performance_str\n",
    "                        elif od1:\n",
    "                            data[0]['A_OD1_SS'] = accuracy_str\n",
    "                            data[0]['P_OD1_SS'] = performance_str\n",
    "                        elif od2:\n",
    "                            data[0]['A_OD2_SS'] = accuracy_str\n",
    "                            data[0]['P_OD2_SS'] = performance_str\n",
    "                        elif nmt:\n",
    "                            data[0]['A_NMT_SS'] = accuracy_str\n",
    "                            data[0]['P_NMT_SS'] = performance_str\n",
    "                    elif scenario_str == 'MultiStream':\n",
    "                        performance_str = '{:d}'.format(num_streams)\n",
    "                        accuracy_str    = '{:.03f}'.format(accuracy)\n",
    "                        if ic1:\n",
    "                            data[0]['A_IC1_MS'] = accuracy_str\n",
    "                            data[0]['P_IC1_MS'] = performance_str\n",
    "                        elif ic2:\n",
    "                            data[0]['A_IC2_MS'] = accuracy_str\n",
    "                            data[0]['P_IC2_MS'] = performance_str\n",
    "                        elif od1:\n",
    "                            data[0]['A_OD1_MS'] = accuracy_str\n",
    "                            data[0]['P_OD1_MS'] = performance_str\n",
    "                        elif od2:\n",
    "                            data[0]['A_OD2_MS'] = accuracy_str\n",
    "                            data[0]['P_OD2_MS'] = performance_str\n",
    "                        elif nmt:\n",
    "                            data[0]['A_NMT_MS'] = accuracy_str\n",
    "                            data[0]['P_NMT_MS'] = performance_str\n",
    "                    elif scenario_str == 'Server':\n",
    "                        performance_str = '{:.03f}'.format(queries_per_second)\n",
    "                        accuracy_str    = '{:.03f}'.format(accuracy)\n",
    "                        if ic1:\n",
    "                            data[0]['A_IC1_S'] = accuracy_str\n",
    "                            data[0]['P_IC1_S'] = performance_str\n",
    "                        elif ic2:\n",
    "                            data[0]['A_IC2_S'] = accuracy_str\n",
    "                            data[0]['P_IC2_S'] = performance_str\n",
    "                        elif od1:\n",
    "                            data[0]['A_OD1_S'] = accuracy_str\n",
    "                            data[0]['P_OD1_S'] = performance_str\n",
    "                        elif od2:\n",
    "                            data[0]['A_OD2_S'] = accuracy_str\n",
    "                            data[0]['P_OD2_S'] = performance_str\n",
    "                        elif nmt:\n",
    "                            data[0]['A_NMT_S'] = accuracy_str\n",
    "                            data[0]['P_NMT_S'] = performance_str                            \n",
    "                    elif scenario_str == 'Offline':\n",
    "                        performance_str = '{:.03f}'.format(samples_per_second)\n",
    "                        accuracy_str    = '{:.03f}'.format(accuracy)\n",
    "                        if ic1:\n",
    "                            data[0]['A_IC1_O'] = accuracy_str\n",
    "                            data[0]['P_IC1_O'] = performance_str\n",
    "                        elif ic2:\n",
    "                            data[0]['A_IC2_O'] = accuracy_str\n",
    "                            data[0]['P_IC2_O'] = performance_str\n",
    "                        elif od1:\n",
    "                            data[0]['A_OD1_O'] = accuracy_str\n",
    "                            data[0]['P_OD1_O'] = performance_str\n",
    "                        elif od2:\n",
    "                            data[0]['A_OD2_O'] = accuracy_str\n",
    "                            data[0]['P_OD2_O'] = performance_str\n",
    "                        elif nmt:\n",
    "                            data[0]['A_NMT_O'] = accuracy_str\n",
    "                            data[0]['P_NMT_O'] = performance_str\n",
    "                    else:\n",
    "                        print('Skipping unsupported task/scenario combination!')\n",
    "                        continue\n",
    "                # END OF FOR EACH scenario\n",
    "                # For closed, multiple benchmarks can share the same row, so the Benchmark field can be misleading.\n",
    "                if division == 'closed': data[0]['Benchmark'] = ''\n",
    "                if is_last_benchmark or (division == 'open' and submitter == 'dividiti'):\n",
    "                    df = pd.DataFrame(data)\n",
    "                    df = df.set_index(index)\n",
    "                    dfs.append(df)\n",
    "            # END OF FOR EACH benchmark\n",
    "        # END OF FOR EACH system\n",
    "    # END OF FOR EACH submitter\n",
    "# END OF FOR EACH division\n",
    "\n",
    "# Concatenate all thus constructed DataFrames (i.e. stack on top of each other).\n",
    "df = pd.concat(dfs)\n",
    "df.sort_index(ascending=True, inplace=True)\n",
    "# Reset the index, but keep Division and Category there.\n",
    "df = df.reset_index(level=index[2:])\n",
    "# Mimic the official template.\n",
    "columns = [ 'ID', 'Submitter', 'System', 'Benchmark' ]\n",
    "columns += score_columns\n",
    "columns += [ 'Processor', 'Processor #', 'Accelerator', 'Accelerator #', 'Software',\n",
    "            'FF_M', 'FF_D', 'FF_S', 'FF_E', 'Details', 'Code', 'Notes' ]\n",
    "df = df[columns]\n",
    "display_in_full(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total number of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should match the official table.\n",
    "print(\"#Rows: %d\" % len(df))\n",
    "# Performance columns are strings for formatting reasons. Convert the strings to numbers (with NaNs for empty strings),\n",
    "# then count the numbers across the columns and finally sum.\n",
    "print(\"#Results: %d\" % df[performance_columns].apply(pd.to_numeric).count(numeric_only=True, axis=0).sum())\n",
    "print(\"#Results/Closed: %d\" % df.loc['Closed'][performance_columns].apply(pd.to_numeric).count(numeric_only=True, axis=0).sum())\n",
    "print(\"#Results/Open: %d\" % df.loc['Open'][performance_columns].apply(pd.to_numeric).count(numeric_only=True, axis=0).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dump Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "from pandas import ExcelWriter\n",
    "# NB: Cannot use dot for 'v0.5', as otherwise the engine complains about an unknown extension.\n",
    "xlsx_filename = 'MLPerf Inference Results v0_5 (Automatically Generated).xlsx'\n",
    "xlsx_writer = ExcelWriter(xlsx_filename, engine='xlsxwriter', options={'strings_to_urls': True})\n",
    "for division in df.index.unique(level='Division'):\n",
    "    df_d = df.loc[division]\n",
    "    for category in df_d.index.unique(level='Category'):\n",
    "        df_dc = df_d.loc[category]\n",
    "        if division == 'Open':\n",
    "            df_xlsx = df_dc\n",
    "        elif division == 'Closed':\n",
    "            df_xlsx = df_dc.drop(labels=['Benchmark']+accuracy_columns, axis=1)\n",
    "        else:\n",
    "            continue\n",
    "        # Write different division and category results to separate sheets. Omit index.\n",
    "        print('*' * 100)\n",
    "        print('* Division / Category: %s / %s' % (division, category))\n",
    "        print('*' * 100)\n",
    "        if category == 'Research, Development, Other': category = 'RDO' # NB: sheet_name must be =< 31 symbols.\n",
    "        df_xlsx.to_excel(xlsx_writer, sheet_name='{}-{}'.format(division, category), index=False)\n",
    "        display_in_full(df_xlsx)\n",
    "        print('')\n",
    "xlsx_writer.save()\n",
    "!cp \"$xlsx_filename\" ~/Downloads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.set_index(['Submitter', 'System', 'Benchmark', 'Software'], append=True)\n",
    "# def link_code(url): return '<a target=\"_blank\" href=\"{}\">Code</a>'.format(url)\n",
    "# def link_details(url): return '<a target=\"_blank\" href=\"{}\">Details</a>'.format(url)\n",
    "# display_in_full(df.style.format({'Code': link_code, 'Details': link_details}))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
