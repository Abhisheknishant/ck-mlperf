{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [MLPerf Inference v0.5](https://github.com/mlperf/inference/tree/master/v0.5) - results table generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Includes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython as ip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mp\n",
    "# import seaborn as sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('IPython version: %s' % ip.__version__)\n",
    "print ('Pandas version: %s' % pd.__version__)\n",
    "print ('NumPy version: %s' % np.__version__)\n",
    "print ('Matplotlib version: %s' % mp.__version__)\n",
    "# print ('Seaborn version: %s' % sb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "def display_in_full(df):\n",
    "    pd.options.display.max_columns = len(df.columns)\n",
    "    pd.options.display.max_rows = len(df.index)\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divisions, categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "divisions = [ 'closed', 'open' ]\n",
    "categories = [ 'available',  'preview', 'RDI', 'RDO' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maps for DataFrame construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase or camelcase to camelcase.\n",
    "scenario_to_str = {\n",
    "    'SingleStream' : 'SingleStream',\n",
    "    'singlestream' : 'SingleStream',\n",
    "\n",
    "    'MultiStream'  : 'MultiStream',\n",
    "    'multistream'  : 'MultiStream',\n",
    "\n",
    "    'Server'       : 'Server',\n",
    "    'server'       : 'Server',\n",
    "\n",
    "    'Offline'      : 'Offline',\n",
    "    'offline'      : 'Offline',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividiti-specific.\n",
    "system_id_to_processor = {\n",
    "    'firefly'   : 'Rockchip RK3399',\n",
    "    'hikey960'  : 'HiSilicon Kirin960',\n",
    "    'mate10pro' : 'HiSilicon Kirin970',\n",
    "    'rpi4'      : 'Broadcom BCM2711B0',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-imagenet benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_imagenet_benchmarks = {\n",
    "    # Non-ImageNet benchmarks from the closed division.\n",
    "    'ssd-small': {\n",
    "        \"name\"  : \"SSD-MobileNet-v1\",\n",
    "        \"width\" : 300,\n",
    "        \"height\": 300,\n",
    "    },\n",
    "    'ssd-large': {\n",
    "        \"name\"  : \"SSD-ResNet34\",\n",
    "        \"width\" : 1200,\n",
    "        \"height\": 1200,\n",
    "    },\n",
    "    'gnmt' : {\n",
    "        \"name\"  : \"GNMT\",\n",
    "        \"width\" : -1,\n",
    "        \"height\": -1,\n",
    "    },\n",
    "    # Non-ImageNet benchmarks from the open division.\n",
    "    'rcnn-nas-lowproposals' : {\n",
    "        \"name\" : \"Faster-RCNN-NAS lowproposals\",\n",
    "        \"url\" : \"http://download.tensorflow.org/models/object_detection/faster_rcnn_nas_lowproposals_coco_2018_01_28.tar.gz\",\n",
    "        \"width\" : 1200,\n",
    "        \"height\" : 1200,\n",
    "    },\n",
    "    'rcnn-resnet50-lowproposals' : {\n",
    "        \"name\" : \"Faster-RCNN-ResNet50 lowproposals\",\n",
    "        \"url\" : \"http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet50_lowproposals_coco_2018_01_28.tar.gz\",\n",
    "        \"width\" : 1024,\n",
    "        \"height\" : 600,\n",
    "    },\n",
    "    'rcnn-resnet101-lowproposals' : {\n",
    "        \"name\" : \"Faster-RCNN-ResNet101 lowproposals\",\n",
    "        \"url\" : \"http://download.tensorflow.org/models/object_detection/faster_rcnn_resnet101_lowproposals_coco_2018_01_28.tar.gz\",\n",
    "        \"width\" : 1024,\n",
    "        \"height\" : 600,\n",
    "    },\n",
    "    'rcnn-inception-resnet-v2-lowproposals' : {\n",
    "        \"name\" : \"Faster-RCNN-Inception-ResNet-v2 lowproposals\",\n",
    "        \"url\" : \"http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_resnet_v2_atrous_lowproposals_coco_2018_01_28.tar.gz\",\n",
    "        \"width\" : 1024,\n",
    "        \"height\" : 600,\n",
    "    },\n",
    "    'rcnn-inception-v2' : {\n",
    "        \"name\" : \"Faster-RCNN Inception-v2\",\n",
    "        \"url\" : \"http://download.tensorflow.org/models/object_detection/faster_rcnn_inception_v2_coco_2018_01_28.tar.gz\",\n",
    "        \"width\" : 1024,\n",
    "        \"height\" : 600,\n",
    "    },\n",
    "    'ssd-inception-v2' : {\n",
    "        \"name\" : \"SSD-Inception-v2\",\n",
    "        \"url\" : \"http://download.tensorflow.org/models/object_detection/ssd_inception_v2_coco_2018_01_28.tar.gz\",\n",
    "        \"width\" : 300,\n",
    "        \"height\" : 300,\n",
    "    },\n",
    "    'ssd-mobilenet-v1-quantized-mlperf' : {\n",
    "        \"name\" : \"SSD-MobileNet-v1\",\n",
    "        \"url\" : \"https://zenodo.org/record/3361502/files/ssd_mobilenet_v1_coco_2018_01_28.tar.gz\",\n",
    "        \"width\" : 300,\n",
    "        \"height\" : 300,\n",
    "        \"provenance\" : \"Google\",\n",
    "    },\n",
    "    'ssd-mobilenet-v1-non-quantized-mlperf' : {\n",
    "        \"name\" : \"SSD-MobileNet-v1 quantized\",\n",
    "        \"url\" : \"https://zenodo.org/record/3252084/files/mobilenet_v1_ssd_8bit_finetuned.tar.gz\",\n",
    "        \"width\" : 300,\n",
    "        \"height\" : 300,\n",
    "        \"provenance\" : \"Habana\"\n",
    "    },\n",
    "    'ssd-mobilenet-v1-fpn' : {\n",
    "        \"name\" : \"SSD-MobileNet-v1 FPN SBP\",\n",
    "        \"url\" : \"http://download.tensorflow.org/models/object_detection/ssd_mobilenet_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03.tar.gz\",\n",
    "        \"width\" : 640,\n",
    "        \"height\" : 640,\n",
    "    },\n",
    "    'ssd-resnet50-fpn' : {\n",
    "        \"name\" : \"SSD-ResNet50-v1 FPN SBP\",\n",
    "        \"url\" : \"http://download.tensorflow.org/models/object_detection/ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03.tar.gz\",\n",
    "        \"width\" : 640,\n",
    "        \"height\" : 640,\n",
    "    },\n",
    "    'ssdlite-mobilenet-v2' : {\n",
    "        \"name\" : \"SSDLite-MobileNet-v2\",\n",
    "        \"url\" : \"http://download.tensorflow.org/models/object_detection/ssdlite_mobilenet_v2_coco_2018_05_09.tar.gz\",\n",
    "        \"width\" : 300,\n",
    "        \"height\" : 300,\n",
    "    },\n",
    "    'yolo-v3' : {\n",
    "        \"name\" : \"YOLO-v3\",\n",
    "        \"url\" : \"https://zenodo.org/record/3386327/files/yolo_v3_coco.tar.gz\",\n",
    "        \"width\" : 416,\n",
    "        \"height\" : 416,\n",
    "        \"provenance\" : \"https://github.com/YunYang1994/tensorflow-yolov3/\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = '/home/anton/projects/mlperf/submissions_inference_0_5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "for division in divisions:\n",
    "    submitters_dir = os.path.join(results_path, division)\n",
    "    if division != 'open': continue # skip closed for now.\n",
    "    for submitter in os.listdir(submitters_dir):\n",
    "        if submitter not in [ 'Qualcomm' ]: continue # [ 'dividiti', 'Qualcomm' ]\n",
    "        systems_dir = os.path.join(submitters_dir, submitter, 'systems')\n",
    "        results_dir = os.path.join(submitters_dir, submitter, 'results')\n",
    "        pprint(results_dir)\n",
    "        for system in os.listdir(results_dir):\n",
    "            if system=='compliance_checker_log.txt': continue\n",
    "            system_dir = os.path.join(results_dir, system)\n",
    "            system_json_name = system+'.json'\n",
    "            with open(os.path.join(systems_dir, system_json_name)) as system_json_file:\n",
    "                system_json = json.load(system_json_file)\n",
    "            for benchmark in os.listdir(system_dir):\n",
    "                if benchmark=='compliance_checker_log.txt': continue\n",
    "                benchmark_dir = os.path.join(system_dir, benchmark)\n",
    "                # TODO: Iterate over scenarios.\n",
    "                for scenario in os.listdir(benchmark_dir):\n",
    "                    if scenario.lower() not in [ 'singlestream', 'multistream' ]: continue\n",
    "                    experiment_dir = os.path.join(benchmark_dir, scenario)\n",
    "                    # Extract accuracy in percent.\n",
    "                    accuracy_dir = os.path.join(experiment_dir, 'accuracy')\n",
    "                    with open(os.path.join(accuracy_dir, 'accuracy.txt'), 'r') as accuracy_file:\n",
    "                        accuracy_txt = accuracy_file.readlines()\n",
    "                        accuracy_line = accuracy_txt[-1]\n",
    "                    if accuracy_line.startswith('mAP'):\n",
    "                        task = 'OD'\n",
    "                        match = re.match('mAP\\=([\\d\\.]+)\\%', accuracy_line)\n",
    "                        accuracy_pc = float(match.group(1))\n",
    "                    elif accuracy_line.startswith('accuracy'):\n",
    "                        task = 'IC'\n",
    "                        match = re.match('accuracy=(.+)%, good=(\\d+), total=(\\d+)', accuracy_line)\n",
    "                        accuracy_pc = float(match.group(1))\n",
    "                    else:\n",
    "                        task = 'MT'\n",
    "                    # Extract 90th percentile for SingleStream from the 6th line. TODO: Extract scores for the other scenarios.\n",
    "                    performance_dir = os.path.join(experiment_dir, 'performance', 'run_1')\n",
    "                    with open(os.path.join(performance_dir, 'mlperf_log_summary.txt'), 'r') as summary_file:\n",
    "                        summary_txt = summary_file.readlines()\n",
    "                        time_ns = int(summary_txt[6].split(':')[1].strip())\n",
    "                        time_ms = time_ns * 1e-6\n",
    "                    benchmark_dict = non_imagenet_benchmarks.get(benchmark)\n",
    "\n",
    "                    # Extract input resolution.\n",
    "                    if benchmark_dict:\n",
    "                        width = benchmark_dict['width']\n",
    "                        height = benchmark_dict['height']\n",
    "                    else:\n",
    "                        if benchmark.endswith('96'):\n",
    "                            side = 96\n",
    "                        elif benchmark.endswith('128'):\n",
    "                            side = 128\n",
    "                        elif benchmark.endswith('160'):\n",
    "                            side = 160\n",
    "                        elif benchmark.endswith('192'):\n",
    "                            side = 192\n",
    "                        else:\n",
    "                            side = 224\n",
    "                        width = side\n",
    "                        height = side\n",
    "\n",
    "                    # System details.\n",
    "                    system_name = system_json['system_name']\n",
    "                    system_list = system.split('-')\n",
    "                    system_id = system_list[0]\n",
    "\n",
    "                    # Processor (CPU).\n",
    "                    processor = system_id_to_processor.get(system_id, system_json['host_processor_model_name'])\n",
    "                    processor_num = system_json['host_processors_per_node']\n",
    "\n",
    "                    # Accelerator.\n",
    "                    accelerator = system_json['accelerator_model_name']\n",
    "                    accelerator_num = system_json['accelerators_per_node']\n",
    "\n",
    "                    # Software (framework).\n",
    "                    software = system_json['framework']\n",
    "\n",
    "                    # Benchmark (width x height).\n",
    "                    benchmark_with_notes = '{} ({}x{})'.format(benchmark, width, height)\n",
    "\n",
    "                    # Tasks.\n",
    "                    ic1 = (task=='IC' and benchmark.startswith('mobilenet'))\n",
    "                    ic2 = (task=='IC' and benchmark=='resnet')\n",
    "                    od1 = (task=='OD' and benchmark=='ssd-mobilenet') # FIXME: benchmark==ssd-small?\n",
    "                    od2 = (task=='OD' and system_id=='velociti')      # FIXME: benchmark==ssd-large?\n",
    "                    nmt = False # TODO: Detect task and model.\n",
    "\n",
    "                    # Default form factors and notes.\n",
    "                    ff_m = ff_d = ff_s = ff_e = ''\n",
    "                    notes = ''\n",
    "\n",
    "                    # Submitter-specific form factors and notes.\n",
    "                    submitter_str = submitter\n",
    "                    if submitter == 'dividiti':\n",
    "                        # Form factors.\n",
    "                        if system_id in [ 'hikey960', 'firefly', 'rpi4' ]: ff_e = 'x'\n",
    "                        if system_id in [ 'mate10pro', 'hikey960' ]: ff_m = 'x'\n",
    "                        if system_id in [ 'velociti' ]: ff_d = 'x'                            \n",
    "                        # Notes.\n",
    "                        if system == 'velociti-tensorflow-v1.14-cpu':\n",
    "                            notes = 'In the Other category, since this Intel CPU is no longer available (end-of-life).'\n",
    "                        if system_id == 'hikey960':\n",
    "                            notes = 'Mobile chip in embedded form factor (development board).'\n",
    "                        # Object Detection is collaboration between dividiti and Politecnico di Milano.\n",
    "                        if task == 'OD': submitter_str = 'dividiti + PoliMi'\n",
    "                    elif submitter == 'Qualcomm':\n",
    "                        notes = 'Median latency. MultiStream: Both Hexagon Vector Extensions (HVX) and Hexagon Tensor Accelerator (HTA).'\n",
    "                            \n",
    "                    # Prepare DataFrame data and index.\n",
    "                    data = [{\n",
    "                        # \n",
    "                        'ID': '-', # TODO: Fill in later.\n",
    "                        'Submitter': submitter_str,\n",
    "                        'System': system_name,\n",
    "                        # TODO: Drop for Closed. Rename to 'Model used, if not Closed Division default' for Open.\n",
    "                        'Benchmark': benchmark_with_notes,\n",
    "                        # Performance metrics (FIXME: stream in ms, multistream in #streams, server in QPS, offline in inputs/s).\n",
    "                        'P_IC1_SS' : '{:.03f}'.format(time_ms) if ic1 and scenario=='singlestream' else '',\n",
    "                        'P_IC1_MS' : '{:.03f}'.format(time_ms) if ic1 and scenario=='multistream'  else '',\n",
    "                        'P_IC1_S'  : '{:.03f}'.format(time_ms) if ic1 and scenario=='server'       else '',\n",
    "                        'P_IC1_O'  : '{:.03f}'.format(time_ms) if ic1 and scenario=='offline'      else '',\n",
    "                        'P_OD1_SS' : '{:.03f}'.format(time_ms) if od1 and scenario=='singlestream' else '',\n",
    "                        'P_OD1_MS' : '{:.03f}'.format(time_ms) if od1 and scenario=='multistream'  else '',\n",
    "                        'P_OD1_S'  : '{:.03f}'.format(time_ms) if od1 and scenario=='server'       else '',\n",
    "                        'P_OD1_O'  : '{:.03f}'.format(time_ms) if od1 and scenario=='offline'      else '',\n",
    "                        'P_IC2_SS' : '{:.03f}'.format(time_ms) if ic2 and scenario=='singlestream' else '',\n",
    "                        'P_IC2_MS' : '{:.03f}'.format(time_ms) if ic2 and scenario=='multistream'  else '',\n",
    "                        'P_IC2_S'  : '{:.03f}'.format(time_ms) if ic2 and scenario=='server'       else '',\n",
    "                        'P_IC2_O'  : '{:.03f}'.format(time_ms) if ic2 and scenario=='offline'      else '',\n",
    "                        'P_OD2_SS' : '{:.03f}'.format(time_ms) if od2 and scenario=='singlestream' else '',\n",
    "                        'P_OD2_MS' : '{:.03f}'.format(time_ms) if od2 and scenario=='multistream'  else '',\n",
    "                        'P_OD2_S'  : '{:.03f}'.format(time_ms) if od2 and scenario=='server'       else '',\n",
    "                        'P_OD2_O'  : '{:.03f}'.format(time_ms) if od2 and scenario=='offline'      else '',\n",
    "                        'P_NMT_SS' : ''                        if nmt and scenario=='singlestream' else '',\n",
    "                        'P_NMT_MS' : ''                        if nmt and scenario=='multistream'  else '',\n",
    "                        'P_NMT_S'  : ''                        if nmt and scenario=='server'       else '',\n",
    "                        'P_NMT_O'  : ''                        if nmt and scenario=='offline'      else '',\n",
    "                        # Accuracy metrics (Top1 for image classification, mAP for object detection, BLEU for machine translation).\n",
    "                        # TODO: Drop for Closed.\n",
    "                        'A_IC1_SS' : '{:.03f}'.format(accuracy_pc) if ic1 and scenario=='singlestream' else '',\n",
    "                        'A_IC1_MS' : '{:.03f}'.format(accuracy_pc) if ic1 and scenario=='multistream'  else '',\n",
    "                        'A_IC1_S'  : '{:.03f}'.format(accuracy_pc) if ic1 and scenario=='server'       else '',\n",
    "                        'A_IC1_O'  : '{:.03f}'.format(accuracy_pc) if ic1 and scenario=='offline'      else '',\n",
    "                        'A_OD1_SS' : '{:.03f}'.format(accuracy_pc) if od1 and scenario=='singlestream' else '',\n",
    "                        'A_OD1_MS' : '{:.03f}'.format(accuracy_pc) if od1 and scenario=='multistream'  else '',\n",
    "                        'A_OD1_S'  : '{:.03f}'.format(accuracy_pc) if od1 and scenario=='server'       else '',\n",
    "                        'A_OD1_O'  : '{:.03f}'.format(accuracy_pc) if od1 and scenario=='offline'      else '',      \n",
    "                        'A_IC2_SS' : '{:.03f}'.format(accuracy_pc) if ic2 and scenario=='singlestream' else '',\n",
    "                        'A_IC2_MS' : '{:.03f}'.format(accuracy_pc) if ic2 and scenario=='multistream'  else '',\n",
    "                        'A_IC2_S'  : '{:.03f}'.format(accuracy_pc) if ic2 and scenario=='server'       else '',\n",
    "                        'A_IC2_O'  : '{:.03f}'.format(accuracy_pc) if ic2 and scenario=='offline'      else '',\n",
    "                        'A_OD2_SS' : '{:.03f}'.format(accuracy_pc) if od2 and scenario=='singlestream' else '',\n",
    "                        'A_OD2_MS' : '{:.03f}'.format(accuracy_pc) if od2 and scenario=='multistream'  else '',\n",
    "                        'A_OD2_S'  : '{:.03f}'.format(accuracy_pc) if od2 and scenario=='server'       else '',\n",
    "                        'A_OD2_O'  : '{:.03f}'.format(accuracy_pc) if od2 and scenario=='offline'      else '',      \n",
    "                        'A_NMT_SS' : ''                            if nmt and scenario=='singlestream' else '',\n",
    "                        'A_NMT_MS' : ''                            if nmt and scenario=='multistream'  else '',\n",
    "                        'A_NMT_S'  : ''                            if nmt and scenario=='server'       else '',\n",
    "                        'A_NMT_O'  : ''                            if nmt and scenario=='offline'      else '',\n",
    "                        # Processor.\n",
    "                        'Processor'     : processor,\n",
    "                        'Processor #'   : processor_num,\n",
    "                        # Accelerator.\n",
    "                        'Accelerator'   : accelerator,\n",
    "                        'Accelerator #' : accelerator_num if accelerator_num != '0' else '',\n",
    "                        # Software.\n",
    "                        'Software' : software,\n",
    "                        # Form factor.\n",
    "                        'FF_M'     : ff_m,\n",
    "                        'FF_D'     : ff_d,\n",
    "                        'FF_S'     : ff_s,\n",
    "                        'FF_E'     : ff_e,\n",
    "                        # Details. Code. Notes.\n",
    "                        'Details'  : 'https://github.com/mlperf/submissions_inference_0_5/blob/master/{}/{}/systems/{}'. \\\n",
    "                                    format(division, submitter, system_json_name),\n",
    "                        'Code'     : 'https://github.com/mlperf/submissions_inference_0_5/tree/master/{}/{}/code'. \\\n",
    "                                    format(division, submitter),\n",
    "                        'Notes'    : notes,\n",
    "                        # Misc.\n",
    "                        'Division' : division,\n",
    "                        'Category' : system_json['status'],\n",
    "                        'Task'     : task,\n",
    "                        'Scenario' : scenario_to_str.get(scenario, scenario),\n",
    "                    }]\n",
    "                    index = [\n",
    "                        'Division', 'Category', 'Submitter', 'System', 'Task', 'Benchmark', 'Scenario', 'Software'\n",
    "                    ]\n",
    "                    # Construct a DataFrame.\n",
    "                    df = pd.DataFrame(data)\n",
    "                    df = df.set_index(index)\n",
    "                    # Append to the list of similarly constructed DataFrames.\n",
    "                    dfs.append(df)\n",
    "\n",
    "                if dfs:\n",
    "                    # Concatenate all thus constructed DataFrames (i.e. stack on top of each other).\n",
    "                    df = pd.concat(dfs)\n",
    "                    df.sort_index(ascending=False, inplace=True)\n",
    "                    # Reset the index, but keep Division and Category there.\n",
    "                    df = df.reset_index(level=index[2:])\n",
    "                    # Mimic official template.\n",
    "                    columns = [\n",
    "                        'ID', 'Submitter', 'System', 'Benchmark',\n",
    "                        'P_IC1_SS', 'P_IC1_MS', 'P_IC1_S', 'P_IC1_O',\n",
    "                        'P_OD1_SS', 'P_OD1_MS', 'P_OD1_S', 'P_OD1_O',\n",
    "                        'P_IC2_SS', 'P_IC2_MS', 'P_IC2_S', 'P_IC2_O',\n",
    "                        'P_OD2_SS', 'P_OD2_MS', 'P_OD2_S', 'P_OD2_O',\n",
    "                        'P_NMT_SS', 'P_NMT_MS', 'P_NMT_S', 'P_NMT_O',\n",
    "                        'A_IC1_SS', 'A_IC1_MS', 'A_IC1_S', 'A_IC1_O',\n",
    "                        'A_OD1_SS', 'A_OD1_MS', 'A_OD1_S', 'A_OD1_O',\n",
    "                        'A_IC2_SS', 'A_IC2_MS', 'A_IC2_S', 'A_IC2_O',\n",
    "                        'A_OD2_SS', 'A_OD2_MS', 'A_OD2_S', 'A_OD2_O',\n",
    "                        'A_NMT_SS', 'A_NMT_MS', 'A_NMT_S', 'A_NMT_O',\n",
    "                        'Processor'  , 'Processor #'  ,\n",
    "                        'Accelerator', 'Accelerator #',\n",
    "                        'Software',\n",
    "                        'FF_M', 'FF_D', 'FF_S', 'FF_E',\n",
    "                        'Details', 'Code', 'Notes'\n",
    "                    ]\n",
    "                    df = df[columns]\n",
    "\n",
    "            # END OF FOR EACH benchmark\n",
    "        # END OF FOR EACH system\n",
    "    # END OF FOR EACH submitter\n",
    "# END OF FOR EACH division\n",
    "\n",
    "def link_code(url): return '<a target=\"_blank\" href=\"{}\">Code</a>'.format(url)\n",
    "def link_details(url): return '<a target=\"_blank\" href=\"{}\">Details</a>'.format(url)\n",
    "display_in_full(df.style.format({'Code': link_code, 'Details': link_details}))\n",
    "\n",
    "# Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "from pandas import ExcelWriter\n",
    "xlsx_filename = 'submissions_inference_0_5.xlsx'\n",
    "xlsx_writer = ExcelWriter(xlsx_filename, engine='xlsxwriter', options={'strings_to_urls': True})\n",
    "for division in df.index.unique(level='Division'):\n",
    "    df_d = df.loc[division]\n",
    "    for category in df_d.index.unique(level='Category'):\n",
    "        df_dc = df_d.loc[category]\n",
    "        if division == 'open':\n",
    "            df_xlsx = df_dc\n",
    "        elif division == 'closed':\n",
    "            # Show MobileNet and ResNet on the same row.\n",
    "            df_mobilenet = df_dc[df_dc['Benchmark']=='mobilenet (224x224)']\n",
    "            df_resnet    = df_dc[df_dc['Benchmark']=='resnet (224x224)']\n",
    "            df_joined    = df_mobilenet.assign(\n",
    "                P_IC2_SS=df_resnet['P_IC2_SS'].values,\n",
    "                A_IC2_MS=df_resnet['A_IC2_SS'].values,\n",
    "#                 P_IC2_MS=df_resnet['P_IC2_MS'].values,\n",
    "#                 A_IC2_SS=df_resnet['A_IC2_MS'].values,\n",
    "#                 P_IC2_S=df_resnet['P_IC2_S'].values,\n",
    "#                 A_IC2_S=df_resnet['A_IC2_S'].values,                \n",
    "#                 P_IC2_O=df_resnet['P_IC2_O'].values,\n",
    "#                 A_IC2_O=df_resnet['A_IC2_O'].values,\n",
    "            )\n",
    "            accuracy_columns = [\n",
    "                'A_{}_{}'.format(task, scenario)\n",
    "                for task in ['IC1','OD1','IC2','OD2','NMT']\n",
    "                for scenario in ['SS','MS','S','O']\n",
    "            ]\n",
    "            df_xlsx = df_joined.drop(labels=['Benchmark']+accuracy_columns, axis=1)\n",
    "        else:\n",
    "            continue\n",
    "        # Write different division and category results to separate sheets. Omit index.\n",
    "        df_xlsx.to_excel(xlsx_writer, sheet_name='{}-{}'.format(division, category), index=False)\n",
    "        display_in_full(df_xlsx)\n",
    "        \n",
    "xlsx_writer.save()\n",
    "!cp $xlsx_filename ~/Downloads"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
